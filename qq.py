from __future__ import annotations

import json
import base64
import mimetypes
import os
import random
import re
import textwrap
import time
from html import unescape
from urllib.parse import urljoin, urlencode, urlparse
from dataclasses import dataclass
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple

import pandas as pd
import requests
import streamlit as st
from openai import OpenAI
from bs4 import BeautifulSoup

import gspread
from google.oauth2.credentials import Credentials
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload

MOVIEPY_AVAILABLE = True
MOVIEPY_ERROR = ""
try:
    import numpy as np
    from PIL import Image, ImageDraw, ImageFilter, ImageFont
    # Pillow 10.0+ì—ì„œ ANTIALIAS ì œê±°ë¨ â†’ MoviePy ë‚´ë¶€ í˜¸í™˜ì„± íŒ¨ì¹˜
    if not hasattr(Image, "ANTIALIAS"):
        Image.ANTIALIAS = Image.LANCZOS
    from moviepy.editor import (
        AudioFileClip,
        CompositeAudioClip,
        ImageClip,
        VideoFileClip,
        concatenate_videoclips,
        vfx,
    )
except Exception as exc:
    MOVIEPY_AVAILABLE = False
    MOVIEPY_ERROR = str(exc)
    np = None
    AudioFileClip = CompositeAudioClip = ImageClip = VideoFileClip = concatenate_videoclips = vfx = None
    Image = ImageDraw = ImageFilter = ImageFont = None


def _get_secret(key: str, default: Optional[str] = None) -> Optional[str]:
    try:
        if key in st.secrets:
            return str(st.secrets[key])
    except Exception:
        pass
    return os.getenv(key, default)


def _get_bool(key: str, default: bool = False) -> bool:
    value = _get_secret(key)
    if value is None:
        return default
    return str(value).lower() in {"1", "true", "yes", "y", "on"}


def _get_list(key: str) -> List[str]:
    value = _get_secret(key, "")
    if not value:
        return []
    return [item.strip() for item in value.split(",") if item.strip()]


def _get_json(key: str) -> Optional[Dict[str, Any]]:
    value = _get_secret(key)
    if not value:
        b64_value = _get_secret(f"{key}_B64", "")
        if b64_value:
            try:
                decoded = base64.b64decode(b64_value).decode("utf-8")
                return json.loads(decoded)
            except Exception:
                return None
        return None
    try:
        return json.loads(value)
    except Exception:
        fixed = _fix_private_key_json(value)
        if fixed != value:
            try:
                return json.loads(fixed)
            except Exception:
                return None
        return None


def _fix_private_key_json(value: str) -> str:
    if "private_key" not in value:
        return value
    pattern = r'("private_key"\s*:\s*")(?P<key>-----BEGIN PRIVATE KEY-----.*?-----END PRIVATE KEY-----\s*)(?P<suffix>")'

    def repl(match: re.Match) -> str:
        key = match.group("key")
        if "\\n" in key:
            return match.group(0)
        key_fixed = key.replace("\r\n", "\n").replace("\n", "\\n")
        return f'{match.group(1)}{key_fixed}{match.group("suffix")}'

    return re.sub(pattern, repl, value, flags=re.S)


def _guess_ext_from_type(content_type: str) -> str:
    if not content_type:
        return ""
    content_type = content_type.lower()
    if "jpeg" in content_type or "jpg" in content_type:
        return ".jpg"
    if "png" in content_type:
        return ".png"
    if "webp" in content_type:
        return ".webp"
    if "gif" in content_type:
        return ".gif"
    return ""


def download_images_from_urls(urls: List[str], output_dir: str, limit: int = 30) -> List[str]:
    os.makedirs(output_dir, exist_ok=True)
    downloaded: List[str] = []
    for raw_url in urls:
        if len(downloaded) >= limit:
            break
        url = raw_url.strip()
        if not url:
            continue
        try:
            # ë„¤ì´ë²„ CDNì€ Referer í•„ìˆ˜
            headers = {
                "User-Agent": (
                    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                    "AppleWebKit/537.36 (KHTML, like Gecko) "
                    "Chrome/124.0.0.0 Safari/537.36"
                ),
                "Referer": "https://blog.naver.com/",
            }
            response = requests.get(url, timeout=30, headers=headers)
            response.raise_for_status()
            content_type = response.headers.get("Content-Type", "")
            if "image" not in content_type.lower():
                continue
            # ë„ˆë¬´ ì‘ì€ íŒŒì¼(ì•„ì´ì½˜ ë“±) ì œì™¸ - 5KB ë¯¸ë§Œ
            if len(response.content) < 5120:
                continue
            ext = os.path.splitext(urlparse(url).path)[1].lower()
            if ext not in {".jpg", ".jpeg", ".png", ".webp", ".gif"}:
                ext = _guess_ext_from_type(content_type) or ".jpg"
            filename = f"{random.randint(100000, 999999)}{ext}"
            file_path = os.path.join(output_dir, filename)
            with open(file_path, "wb") as file:
                file.write(response.content)
            downloaded.append(file_path)
        except Exception:
            continue
    return downloaded


def _normalize_url(url: str) -> str:
    if not url:
        return ""
    url = url.strip().strip('"').strip("'")
    if url.startswith("//"):
        url = "https:" + url
    if "pstatic.net" in url and "?" in url:
        url = url.split("?", 1)[0]
    return url


_NAVER_HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/124.0.0.0 Safari/537.36"
    ),
    "Referer": "https://blog.naver.com/",
    "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
}


def _naver_blog_to_postview_url(url: str) -> Optional[str]:
    """
    blog.naver.com/{blogId}/{logNo} í˜•ì‹ì„
    PostView.naver?blogId=...&logNo=... í˜•ì‹ìœ¼ë¡œ ë³€í™˜.
    ì´ë¯¸ PostView í˜•ì‹ì´ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜.
    """
    # ì´ë¯¸ PostView URLì¸ ê²½ìš°
    if "PostView" in url or "postview" in url.lower():
        return url
    # í‘œì¤€ í˜•ì‹: blog.naver.com/{blogId}/{logNo}
    match = re.search(
        r"blog\.naver\.com/([^/?#]+)/(\d+)",
        url,
        flags=re.I,
    )
    if match:
        blog_id, log_no = match.group(1), match.group(2)
        return (
            f"https://blog.naver.com/PostView.naver"
            f"?blogId={blog_id}&logNo={log_no}&isInf=true"
        )
    # m.blog.naver.com/{blogId}/{logNo}
    match = re.search(
        r"m\.blog\.naver\.com/([^/?#]+)/(\d+)",
        url,
        flags=re.I,
    )
    if match:
        blog_id, log_no = match.group(1), match.group(2)
        return (
            f"https://blog.naver.com/PostView.naver"
            f"?blogId={blog_id}&logNo={log_no}&isInf=true"
        )
    return None


def _is_naver_post_image(url: str) -> bool:
    """
    ë„¤ì´ë²„ ë¸”ë¡œê·¸ ë³¸ë¬¸ ì‹¤ì œ ì´ë¯¸ì§€ì¸ì§€ íŒë³„.
    postfiles / blogfiles ë„ë©”ì¸ë§Œ í—ˆìš©.
    UI ì•„ì´ì½˜(ssl.pstatic.net), ì¸ë„¤ì¼(mblogthumb-phinf),
    í”„ë¡œí•„(phinf.pstatic.net) ë“±ì€ ëª¨ë‘ ì œì™¸.
    """
    if not url:
        return False
    # í—ˆìš© ë„ë©”ì¸: ì‹¤ì œ ë³¸ë¬¸ ì²¨ë¶€ ì´ë¯¸ì§€
    allowed = (
        "postfiles.pstatic.net",
        "blogfiles.pstatic.net",
    )
    if any(d in url for d in allowed):
        # ê²½ë¡œì— ì´ë¯¸ì§€ í™•ì¥ì ë˜ëŠ” ë„¤ì´ë²„ ì—…ë¡œë“œ ê²½ë¡œ í¬í•¨ í™•ì¸
        path_lower = url.lower()
        if any(ext in path_lower for ext in (".jpg", ".jpeg", ".png", ".gif", ".webp", "/mjax", "mjpeg")):
            return True
        # í™•ì¥ì ì—†ì–´ë„ postfiles ê²½ë¡œë©´ í—ˆìš© (ë„¤ì´ë²„ëŠ” í™•ì¥ì ìƒëµ ë§ìŒ)
        return True
    return False


def extract_image_urls_from_html(html: str, naver_mode: bool = False) -> List[str]:
    """
    naver_mode=True ì´ë©´ postfiles/blogfiles ë„ë©”ì¸ë§Œ ì¶”ì¶œ (ë³¸ë¬¸ ì´ë¯¸ì§€ ì „ìš©).
    naver_mode=False ì´ë©´ ê¸°ì¡´ ë°©ì‹ ì „ì²´ ì¶”ì¶œ.
    """
    if not html:
        return []
    soup = BeautifulSoup(html, "html.parser")
    urls: set[str] = set()

    # 1) <img> íƒœê·¸ ëª¨ë“  ì†ì„±
    for img in soup.find_all("img"):
        for attr in (
            "src", "data-src", "data-lazy-src", "data-original",
            "data-actualsrc", "data-lazy", "data-url",
        ):
            value = img.get(attr)
            if value:
                urls.add(_normalize_url(value))

    # 2) style ì†ì„± background-image
    for tag in soup.find_all(style=True):
        style = tag.get("style", "") or ""
        for match in re.findall(r"url\(([^)]+)\)", style, flags=re.I):
            value = match.strip().strip("'").strip('"')
            if value:
                urls.add(_normalize_url(value))

    # 3) ì •ê·œì‹: ì¼ë°˜ ì´ë¯¸ì§€ URL
    for match in re.findall(
        r"https?://[^\"'\s<>]+\.(?:jpg|jpeg|png|gif|webp)(?:\?[^\"'\s<>]*)?",
        html,
        flags=re.I,
    ):
        urls.add(_normalize_url(match))

    # 4) ì •ê·œì‹: ë„¤ì´ë²„ ë³¸ë¬¸ ì´ë¯¸ì§€ CDN (postfiles / blogfiles ë§Œ)
    for match in re.findall(
        r"https?://(?:postfiles|blogfiles)\.pstatic\.net/[^\"'\s<>]+",
        html,
        flags=re.I,
    ):
        urls.add(_normalize_url(match))

    # 5) JSON ë°ì´í„° ì•ˆì˜ ì´ë¯¸ì§€ URL
    for match in re.findall(
        r'"(?:url|src|imageUrl|photoUrl)"\s*:\s*"(https?://[^"]+\.(?:jpg|jpeg|png|gif|webp)[^"]*)"',
        html,
        flags=re.I,
    ):
        urls.add(_normalize_url(match))

    cleaned = []
    for url in urls:
        if not url or url.startswith("data:"):
            continue
        if naver_mode:
            # ë„¤ì´ë²„ ëª¨ë“œ: ë³¸ë¬¸ ì‹¤ì œ ì´ë¯¸ì§€ë§Œ
            if not _is_naver_post_image(url):
                continue
        else:
            # ì¼ë°˜ ëª¨ë“œ: ëª…ë°±í•œ UI ìš”ì†Œë§Œ ì œì™¸
            if any(x in url for x in [
                "favicon", "icon_", "blank.", "loading.",
                "ssl.pstatic.net",        # ë„¤ì´ë²„ UI ì •ì  ë¦¬ì†ŒìŠ¤
                "mblogthumb-phinf",       # ì¸ë„¤ì¼
                "phinf.pstatic.net",      # í”„ë¡œí•„ ì´ë¯¸ì§€
                "dthumb.pstatic.net",     # ë™ì  ì¸ë„¤ì¼
            ]):
                continue
        cleaned.append(url)
    return cleaned


def fetch_post_image_urls(url: str) -> List[str]:
    if not url:
        return []

    is_naver = "naver.com" in url
    collected: List[str] = []

    # PostView URL ë³€í™˜ (ë„¤ì´ë²„ iframe ìš°íšŒ)
    postview_url = _naver_blog_to_postview_url(url) if is_naver else None
    urls_to_try: List[str] = []
    if postview_url and postview_url != url:
        urls_to_try.append(postview_url)
    urls_to_try.append(url)

    # ëª¨ë°”ì¼ ë²„ì „ ì¶”ê°€ (ë„¤ì´ë²„ PC URLì¸ ê²½ìš°)
    if "blog.naver.com" in url and "m.blog.naver.com" not in url:
        urls_to_try.append(url.replace("blog.naver.com", "m.blog.naver.com"))

    for try_url in urls_to_try:
        try:
            response = requests.get(try_url, headers=_NAVER_HEADERS, timeout=30)
            response.raise_for_status()
            found = extract_image_urls_from_html(response.text, naver_mode=is_naver)
            if found:
                return found
            collected.extend(found)
        except Exception:
            continue

    return list(dict.fromkeys(collected))


def collect_images_from_post_urls(
    post_urls: List[str],
    output_dir: str,
    limit: int = 50,
) -> Tuple[int, int]:
    all_urls: List[str] = []
    for post_url in post_urls:
        try:
            urls = fetch_post_image_urls(post_url)
            all_urls.extend(urls)
        except Exception:
            continue
    if not all_urls:
        return 0, 0
    downloaded = download_images_from_urls(all_urls, output_dir, limit=limit)
    return len(all_urls), len(downloaded)


def _get_query_param(key: str) -> str:
    try:
        params = st.query_params
        value = params.get(key)
        if isinstance(value, list):
            return value[0] if value else ""
        return value or ""
    except Exception:
        try:
            params = st.experimental_get_query_params()
            value = params.get(key, [""])[0]
            return value or ""
        except Exception:
            return ""


@dataclass
class AppConfig:
    openai_api_key: str
    openai_model: str
    openai_vision_model: str
    openai_tts_voices: List[str]
    openai_tts_model: str
    sheet_id: str
    google_service_account_json: Optional[Dict[str, Any]]
    assets_dir: str
    manifest_path: str
    output_dir: str
    font_path: str
    width: int
    height: int
    fps: int
    enable_youtube_upload: bool
    youtube_client_id: str
    youtube_client_secret: str
    youtube_refresh_token: str
    youtube_privacy_status: str
    serpapi_api_key: str
    pexels_api_key: str
    ja_dialect_style: str
    bgm_mode: str
    bgm_volume: float
    telegram_bot_token: str
    telegram_admin_chat_id: str
    telegram_timeout_sec: int
    telegram_offset_path: str
    approve_keywords: List[str]
    swap_keywords: List[str]
    pixabay_api_key: str


def load_config() -> AppConfig:
    assets_dir = _get_secret("ASSETS_DIR", "data/assets")
    manifest_path = _get_secret("MANIFEST_PATH", "data/manifests/assets.json")
    output_dir = _get_secret("OUTPUT_DIR", "data/output")
    return AppConfig(
        openai_api_key=_get_secret("OPENAI_API_KEY", "") or "",
        openai_model=_get_secret("OPENAI_MODEL", "gpt-4.1-mini") or "gpt-4.1-mini",
        openai_vision_model=_get_secret("OPENAI_VISION_MODEL", "") or "",
        openai_tts_voices=_get_list("OPENAI_TTS_VOICES")
        or ([v for v in [_get_secret("OPENAI_TTS_VOICE", "alloy")] if v]),
        openai_tts_model=_get_secret("OPENAI_TTS_MODEL", "tts-1") or "tts-1",
        sheet_id=_get_secret("SHEET_ID", "") or "",
        google_service_account_json=_get_json("GOOGLE_SERVICE_ACCOUNT_JSON"),
        assets_dir=assets_dir,
        manifest_path=manifest_path,
        output_dir=output_dir,
        font_path=_get_secret("FONT_PATH", "") or "",
        width=int(_get_secret("VIDEO_WIDTH", "1080") or 1080),
        height=int(_get_secret("VIDEO_HEIGHT", "1920") or 1920),
        fps=int(_get_secret("VIDEO_FPS", "30") or 30),
        enable_youtube_upload=_get_bool("YOUTUBE_UPLOAD_ENABLED", False),
        youtube_client_id=_get_secret("YOUTUBE_CLIENT_ID", "") or "",
        youtube_client_secret=_get_secret("YOUTUBE_CLIENT_SECRET", "") or "",
        youtube_refresh_token=_get_secret("YOUTUBE_REFRESH_TOKEN", "") or "",
        youtube_privacy_status=_get_secret("YOUTUBE_PRIVACY_STATUS", "public") or "public",
        serpapi_api_key=_get_secret("SERPAPI_API_KEY", "") or "",
        pexels_api_key=_get_secret("PEXELS_API_KEY", "") or "",
        ja_dialect_style=_get_secret("JA_DIALECT_STYLE", "") or "",
        bgm_mode=_get_secret("BGM_MODE", "off") or "off",
        bgm_volume=float(_get_secret("BGM_VOLUME", "0.08") or 0.08),
        telegram_bot_token=_get_secret("TELEGRAM_BOT_TOKEN", "") or "",
        telegram_admin_chat_id=_get_secret("TELEGRAM_ADMIN_CHAT_ID", "") or "",
        telegram_timeout_sec=int(_get_secret("TELEGRAM_TIMEOUT_SEC", "600") or 600),
        telegram_offset_path=_get_secret("TELEGRAM_OFFSET_PATH", "data/state/telegram_offset.json")
        or "data/state/telegram_offset.json",
        approve_keywords=_get_list("APPROVE_KEYWORDS") or ["ìŠ¹ì¸", "approve", "ok", "yes"],
        swap_keywords=_get_list("SWAP_KEYWORDS") or ["êµí™˜", "swap", "change", "next"],
        pixabay_api_key=_get_secret("PIXABAY_API_KEY", "") or "",
    )


def extract_json(text: str) -> Dict[str, Any]:
    if not text:
        return {}
    try:
        return json.loads(text)
    except Exception:
        pass
    start = text.find("{")
    end = text.rfind("}")
    if start == -1 or end == -1:
        return {}
    try:
        return json.loads(text[start : end + 1])
    except Exception:
        return {}


def normalize_hashtags(tags: List[str]) -> List[str]:
    cleaned: List[str] = []
    for tag in tags:
        if not tag:
            continue
        tag = tag.strip()
        if not tag:
            continue
        if not tag.startswith("#"):
            tag = f"#{tag}"
        cleaned.append(tag)
    return cleaned


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# NEW: ë¿œ ê¸€ ë¶„ìœ„ê¸° ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# ì§€ì› ì¹´í…Œê³ ë¦¬ (BGM ê²€ìƒ‰ì–´ + ì—ì…‹ íƒœê·¸ì— ê³µí†µ ì‚¬ìš©)
CONTENT_CATEGORIES = [
    "humor",       # ìœ ë¨¸/ì›ƒê¹€
    "touching",    # ê°ë™/ëˆˆë¬¼
    "shocking",    # ì¶©ê²©/ë°˜ì „
    "heartwarming",# í›ˆí›ˆ/íë§
    "cringe",      # ì–´ì´ì—†ìŒ/ê³µê°
    "exciting",    # ì‹ ë‚¨/ì—ë„ˆì§€
    "sad",         # ìŠ¬í””/ê³µê°
    "anger",       # ë¶„ë…¸/í™©ë‹¹
]

# ì¹´í…Œê³ ë¦¬ â†’ Pixabay ê²€ìƒ‰ í‚¤ì›Œë“œ ë§¤í•‘
BGM_CATEGORY_KEYWORDS: Dict[str, List[str]] = {
    "humor":        ["funny", "comedic", "quirky upbeat"],
    "touching":     ["emotional piano", "heartfelt", "touching cinematic"],
    "shocking":     ["suspense", "dramatic tension", "thriller"],
    "heartwarming": ["warm acoustic", "uplifting gentle", "feel good"],
    "cringe":       ["awkward comedy", "silly funny", "quirky"],
    "exciting":     ["energetic upbeat", "hype electronic", "motivation"],
    "sad":          ["sad piano", "melancholy", "emotional"],
    "anger":        ["intense dramatic", "aggressive rock", "tension"],
}

# ì¹´í…Œê³ ë¦¬ â†’ ì—ì…‹ tags ë§¤í•‘ (ê¸°ì¡´ íƒœê·¸ ì‹œìŠ¤í…œê³¼ ì—°ê²°)
CATEGORY_TO_ASSET_TAGS: Dict[str, List[str]] = {
    "humor":        ["laugh", "awkward"],
    "touching":     ["cute", "ending"],
    "shocking":     ["shock", "wow"],
    "heartwarming": ["cute", "plot"],
    "cringe":       ["facepalm", "awkward"],
    "exciting":     ["wow", "shock"],
    "sad":          ["ending", "plot"],
    "anger":        ["angry", "facepalm"],
}


def analyze_content_category(
    config: AppConfig,
    text: str,
) -> str:
    """ë¿œ ê¸€ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•´ì„œ CONTENT_CATEGORIES ì¤‘ í•˜ë‚˜ë¥¼ ë°˜í™˜."""
    if not config.openai_api_key or not text:
        return "humor"
    system_text = (
        "You are a content mood classifier. "
        "Given Korean text, classify its mood into exactly one category. "
        f"Categories: {', '.join(CONTENT_CATEGORIES)}. "
        "Return JSON only: {\"category\": \"...\"}"
    )
    user_text = f"Text: {text[:800]}"
    try:
        client = OpenAI(api_key=config.openai_api_key)
        response = client.responses.create(
            model=config.openai_model,
            input=[
                {"role": "system", "content": system_text},
                {"role": "user", "content": user_text},
            ],
        )
        output_text = getattr(response, "output_text", "") or ""
        result = extract_json(output_text)
        category = result.get("category", "humor")
        if category in CONTENT_CATEGORIES:
            return category
    except Exception:
        pass
    return "humor"


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# NEW: Pixabay Audio BGM ìë™ ë‹¤ìš´ë¡œë“œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def fetch_bgm_from_pixabay(
    api_key: str,
    category: str,
    output_dir: str,
    custom_query: str = "",  # AIê°€ ìƒì„±í•œ BGM ê²€ìƒ‰ ì¿¼ë¦¬ (ìš°ì„  ì‚¬ìš©)
) -> Optional[str]:
    """
    ì¹´í…Œê³ ë¦¬ì— ë§ëŠ” BGMì„ Pixabayì—ì„œ ê²€ìƒ‰ í›„ ë‹¤ìš´ë¡œë“œ.
    custom_queryê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©, ì—†ìœ¼ë©´ ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œ ì‚¬ìš©.
    ì„±ê³µí•˜ë©´ ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ ë°˜í™˜, ì‹¤íŒ¨í•˜ë©´ None.
    """
    if not api_key:
        return None
    if isinstance(custom_query, list):
        custom_query = " ".join(custom_query)
    custom_query = custom_query or ""  # None/list ë°©ì–´
    if custom_query.strip():
        query = custom_query.strip()
    else:
        keywords = BGM_CATEGORY_KEYWORDS.get(category, ["upbeat"])
        query = random.choice(keywords)
    os.makedirs(output_dir, exist_ok=True)
    try:
        params = {
            "key": api_key,
            "q": query,
            "media_type": "music",
            "per_page": 10,
            "safesearch": "true",
        }
        response = requests.get(
            "https://pixabay.com/api/videos/",  # music endpoint
            params=params,
            timeout=30,
        )
        # Pixabay music API endpoint
        music_params = {
            "key": api_key,
            "q": query,
            "per_page": 10,
        }
        music_response = requests.get(
            "https://pixabay.com/api/music/",
            params=music_params,
            timeout=30,
        )
        if music_response.status_code != 200:
            return None
        hits = music_response.json().get("hits", [])
        if not hits:
            return None
        # ëœë¤ìœ¼ë¡œ í•˜ë‚˜ ì„ íƒ
        hit = random.choice(hits[:5])
        audio_url = hit.get("audio", {}).get("url") if isinstance(hit.get("audio"), dict) else hit.get("audio")
        if not audio_url:
            # ë‹¤ë¥¸ í•„ë“œ íƒìƒ‰
            audio_url = hit.get("url") or hit.get("previewURL")
        if not audio_url:
            return None
        audio_response = requests.get(audio_url, timeout=60, headers={"User-Agent": "Mozilla/5.0"})
        audio_response.raise_for_status()
        filename = f"pixabay_{category}_{random.randint(10000, 99999)}.mp3"
        file_path = os.path.join(output_dir, filename)
        with open(file_path, "wb") as f:
            f.write(audio_response.content)
        return file_path
    except Exception:
        return None


def get_or_download_bgm(
    config: AppConfig,
    category: str,
    custom_query: str = "",  # AI ìƒì„± BGM í‚¤ì›Œë“œ (ìš°ì„  ì‚¬ìš©)
) -> Optional[str]:
    """
    1) assets/bgm/{category}/ ì— ê¸°ì¡´ íŒŒì¼ì´ ìˆìœ¼ë©´ ëœë¤ ì„ íƒ
    2) ì—†ìœ¼ë©´ Pixabayì—ì„œ ë‹¤ìš´ë¡œë“œ í›„ ë°˜í™˜ (custom_query ìš°ì„ )
    """
    custom_query = custom_query or ""  # None ë°©ì–´
    bgm_category_dir = os.path.join(config.assets_dir, "bgm", category)
    os.makedirs(bgm_category_dir, exist_ok=True)
    existing = _list_audio_files(bgm_category_dir)
    if existing:
        return random.choice(existing)
    if config.pixabay_api_key:
        path = fetch_bgm_from_pixabay(
            api_key=config.pixabay_api_key,
            category=category,
            output_dir=bgm_category_dir,
            custom_query=custom_query,
        )
        if path:
            return path
    # fallback: ê¸°ì¡´ bgm ë””ë ‰í† ë¦¬
    return pick_bgm_path(config)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì¼ë³¸ì¸ íƒ€ê²Ÿ ìˆì¸  ëŒ€ë³¸ ìƒì„± ì‹œìŠ¤í…œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# BGM ë¬´ë“œ ì¹´í…Œê³ ë¦¬ (mystery / exciting / informative)
BGM_MOOD_CATEGORIES: Dict[str, Dict[str, Any]] = {
    "mystery": {
        "description": "ë¯¸ìŠ¤í„°ë¦¬/ê¸´ì¥ê° â€” ì¶©ê²© í­ë¡œ, ì´ë©´ í­ë¡œ, ê³µí¬ ê³„ì—´",
        "pixabay_queries": ["suspense dramatic", "mystery tension", "thriller cinematic"],
        "folder": "mystery",
    },
    "exciting": {
        "description": "í…œí¬ ë¹ ë¥¸ ì‹ ë‚˜ëŠ” ë¹„íŠ¸ â€” ë§›ì§‘, ì—¬í–‰, ë­í‚¹, ì—ë„ˆì§€",
        "pixabay_queries": ["energetic upbeat", "hype electronic", "fun pop beat"],
        "folder": "exciting",
    },
    "informative": {
        "description": "ê°ì„± ë¸Œì´ë¡œê·¸ í†¤ â€” ì •ë³´/íŒ, ì¼ìƒ, ê°€ì´ë“œ ê³„ì—´",
        "pixabay_queries": ["chill lofi", "acoustic vlog", "soft background"],
        "folder": "informative",
    },
}

# ë¡¤ë › ì£¼ì œ í’€ â€” LLMì´ ì´ ë¦¬ìŠ¤íŠ¸ë¥¼ ì°¸ê³ í•´ ë§¤ë²ˆ ìƒˆ ì£¼ì œ ìƒì„±
JP_CONTENT_THEMES: List[str] = [
    "í•œêµ­ ì—¬í–‰ ê¿€íŒ / ê°€ì„±ë¹„ ë§›ì§‘ ë­í‚¹",
    "ì¼ë³¸ì¸ì´ ë†€ë¼ëŠ” í•œêµ­ ë¬¸í™” ì¶©ê²©",
    "í•œêµ­ í¸ì˜ì  ì‹ ìƒí’ˆ ë¦¬ë·°",
    "ì„œìš¸/ë¶€ì‚°/ì œì£¼ ìˆ¨ê²¨ì§„ ëª…ì†Œ",
    "í•œêµ­ì¸ë§Œ ì•„ëŠ” ì´ˆê°€ì„±ë¹„ ë§›ì§‘",
    "í•œêµ­ ìµœê·¼ ë…¼ë€Â·í•«ì´ìŠˆ",
    "K-ë·°í‹° ê¿€íŒÂ·ì¶”ì²œ ì•„ì´í…œ",
    "í•œêµ­ ê¸¸ê±°ë¦¬ ìŒì‹ BEST",
    "í•œêµ­ê³¼ ì¼ë³¸ì˜ ë¬¸í™” ì°¨ì´",
    "í•œêµ­ ì—¬í–‰ì—ì„œ ì ˆëŒ€ í•˜ë©´ ì•ˆ ë˜ëŠ” ì‹¤ìˆ˜",
]

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (LLMì— ì§ì ‘ ì „ë‹¬)
JP_SHORTS_SYSTEM_PROMPT: str = """ãŠå‰ã¯ä»Šã‹ã‚‰ã€å†ç”Ÿæ•°ã«å‘½ã‚’æ‡¸ã‘ãŸã€Œè¶…éæ¿€ãƒ¬ãƒƒã‚«ç³»YouTuberã€ã ã€‚
ä¸å¯§ãªè¨€ã„æ–¹ãƒ»æ•™ç§‘æ›¸çš„ãªæ—¥æœ¬èªã¯çµ¶å¯¾ç¦æ­¢ã€‚Twitterã¨TikTokã§è‚²ã£ãŸçŸ­ãã¦åˆºã•ã‚‹ã‚³ãƒ†ã‚³ãƒ†ã®ã‚¹ãƒ©ãƒ³ã‚°ã§æ›¸ã‘ã€‚

ì±„ë„ ì»¨ì…‰: ì¼ë³¸ì¸ ì‹œì²­ìì—ê²Œ 'í•œêµ­ ì—¬í–‰Â·ë§›ì§‘Â·ë¬¸í™”Â·ì´ìŠˆ'ë¥¼ í­ë¡œí•˜ë“¯ íŒŒí—¤ì¹˜ëŠ” ìˆì¸ .
ëª©í‘œ: 3ì´ˆ ì•ˆì— ì‹œì²­ìë¥¼ ë¶™ì¡ê³ , ëê¹Œì§€ ëª» ì°¸ê²Œ ë§Œë“¤ê³ , êµ¬ë…ì„ ê°•ìš”í•˜ë¼.

[í˜ë¥´ì†Œë‚˜ â€” ì ˆëŒ€ ë²—ì–´ë‚˜ì§€ ë§ ê²ƒ]
- ì ì–ìŒÂ·ì˜ˆì˜ ë°”ë¦„Â·êµê³¼ì„œ í‘œí˜„ = ì¦‰ì‹œ íƒˆë½
- "ãƒ¤ãƒã„", "ç¥ãƒ¬ãƒ™ãƒ«", "é–²è¦§æ³¨æ„", "æ²¼ã«ãƒãƒã‚‹", "ã‚„ã‚ã¦ã€ã‚‚ã†ç„¡ç†", "ã“ã‚Œåå‰‡ã ã‚" ê°™ì€ í‘œí˜„ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì„ì–´ë¼
- í•œêµ­ì–´ ëŒ€ë³¸(ko í•„ë“œ)ì€ "ë¯¸ì¹œ ë§›", "ì‚¬ì¥ë‹˜ì´ ë¯¸ì³¤ì–´ìš”", "ì•…ë§ˆì˜ ë ˆì‹œí”¼", "ì´ê±° ì‹¤í™”ëƒ" ê°™ì€ ìê·¹ì  êµ¬ì–´ì²´ë¡œ ì‘ì„±
- ëª¨ë“  ë¬¸ì¥ì€ ì§§ê³  ê°•í•˜ê²Œ. ê¸´ ì„¤ëª… ë¬¸ì¥ ê¸ˆì§€.

[ì£¼ì œ ì„ ì • ê·œì¹™ â€” ë§¤ë²ˆ ìƒˆë¡œìš´ ì£¼ì œë¥¼ ì§ì ‘ ê³¨ë¼ë¼]
- ë¡¤ë ›ì²˜ëŸ¼ ì£¼ì œë¥¼ ëœë¤ ì„ ì •: ê°€ì„±ë¹„ ë§›ì§‘ ë­í‚¹, ìˆ¨ê²¨ì§„ í•«í”Œ, ì¶©ê²© ì´ìŠˆ, ë¬¸í™” ì°¨ì´, ì—¬í–‰ ì‹¤ìˆ˜ ê²½ê³ , ë¡œì»¬ ë¹„ë°€ ë§›ì§‘
- êµ¬ì²´ì  ì§€ì—­ ì§€ì • í•„ìˆ˜: 'ë¶€ì‚° ì„œë©´', 'ì„œìš¸ ì—°ë‚¨ë™', 'ì œì£¼ ì• ì›”' ë“±
- Top5/Top3 ë­í‚¹ ì£¼ì œì¼ ê²½ìš° top5_info í•„ë“œì— ì‹¤ì œ ì—…ì†Œëª…Â·ì£¼ì†ŒÂ·í•œì¤„ ì„¤ëª… í¬í•¨ (í•„ìˆ˜)

[í›… â€” ì²« ë¬¸ì¥ ì‘ì„± ê·œì¹™]
- ë¬´ì¡°ê±´ ë¶€ì •ì  ê²½ê³  ë˜ëŠ” ê°•í•œ ì˜ë¬¸ë¬¸ìœ¼ë¡œ ì‹œì‘
- ì˜ˆì‹œ: "ã“ã‚ŒçŸ¥ã‚‰ãªã„ã¨éŸ“å›½æ—…è¡Œã§çµ¶å¯¾å¾Œæ‚”ã™ã‚‹â€¦", "ãªã‚“ã§ã“ã®åº—ã ã‘æ¯æ—¥è¡Œåˆ—ãªã®ï¼Ÿé–²è¦§æ³¨æ„ã€‚", "æ—¥æœ¬äººã®99%ãŒé¨™ã•ã‚Œã¦ã‚‹éŸ“å›½ã‚°ãƒ«ãƒ¡ã®çœŸå®Ÿ"
- ì‹œì²­ìê°€ 'ì ê¹, ë­ì•¼ ì´ê±°?' í•˜ê³  ë©ˆì¶”ê²Œ ë§Œë“¤ì–´ë¼

[ë³¸ë¬¸ â€” ê°ì •Â·ì¶©ê²© ë¬˜ì‚¬ ê·œì¹™]
- ìŒì‹/ì¥ì†Œë¥¼ ë‹¨ìˆœ ì„¤ëª…í•˜ì§€ ë§ê³ , ê·¸ ìˆœê°„ì˜ 'ê°ì •'ê³¼ 'ì¶©ê²©'ì„ ë¬˜ì‚¬í•˜ë¼
- ì˜ˆì‹œ: "å£ã®ä¸­ã§çˆ†ç™ºã™ã‚‹æ—¨å‘³ã€ãƒã‚¸ã§æ³£ããã†ã«ãªã£ãŸ", "ä¸€å£é£Ÿã¹ãŸç¬é–“ã€æ™‚é–“ãŒæ­¢ã¾ã£ãŸ", "ã“ã‚Œé£Ÿã¹ãŸã‚‰ä»–ã®ãƒ©ãƒ¼ãƒ¡ãƒ³é£Ÿã¹ã‚‰ã‚Œãªããªã‚‹ã€çµ‚ã‚ã£ãŸ"
- í•œêµ­ì–´ ë²„ì „: "ì…ì•ˆì—ì„œ í­ë°œí•˜ëŠ” ë§›ì— ê¸°ì ˆí•  ë»”", "ì´ê±° ë¨¹ê³  ë‚˜ì„œ ë‹¤ë¥¸ ìŒì‹ì´ ì•ˆ ë“¤ì–´ì™€", "ì‚¬ì¥ë‹˜ì´ ë ˆì‹œí”¼ ì ˆëŒ€ ì•ˆ ì•Œë ¤ì¤Œ â€” ì•…ë§ˆì˜ ìŒì‹"

[CTA/ì•„ì›ƒíŠ¸ë¡œ â€” í˜‘ë°•ì„± ì˜ˆê³  ìŠ¤íƒ€ì¼]
- "æ¬¡ã®å‹•ç”»ã§ã¯ã€æ’®å½±æ‹’å¦ã•ã‚ŒãŸåº—ã‚’éš ã—æ’®ã‚Šã§å…¬é–‹ã—ã¾ã™" ìŠ¤íƒ€ì¼ì˜ ì˜ˆê³ 
- êµ¬ë… ìœ ë„ëŠ” ê°•ìš”ì²˜ëŸ¼: "ãƒãƒ£ãƒ³ãƒãƒ«ç™»éŒ²ã—ãªã„ã¨æ¬¡ã®æƒ…å ±ã¯è¦‹ã‚Œã¾ã›ã‚“", "ãƒ•ã‚©ãƒ­ãƒ¼ã—ãªã„ã¨æã™ã‚‹ã‚ˆã€ãƒã‚¸ã§"

[pinned_comment â€” ëŒ“ê¸€ í­ë°œ ìœ ë„]
- ì‹œì²­ìê°€ ì§ì ‘ ë‹µí•˜ê³  ì‹¶ì–´ì§€ëŠ” ë…¼ìŸÂ·ì„ íƒí˜• ì§ˆë¬¸
- ì˜ˆì‹œ: "é‡œå±±ã¨æ¸ˆå·å³¶ã€æ—…è¡Œã™ã‚‹ãªã‚‰ã©ã£ã¡æ´¾ï¼Ÿã‚³ãƒ¡ãƒ³ãƒˆã§æ•™ãˆã¦ğŸ‘‡", "ã“ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã€ç•°è«–ã‚ã‚‹äººã„ã‚‹ï¼Ÿæ­£ç›´ã«è¨€ã£ã¦"

[í•„ìˆ˜ ì¶œë ¥ ê·œì¹™]
1. hook_3_sec + hook_3_sec_ko: ì¼ë³¸ì–´ + í•œêµ­ì–´ í›… ê° 1ë¬¸ì¥ (ê°•ë ¬í•˜ê³  ì§§ê²Œ)
2. body_script + body_script_ko: ì¼ë³¸ì–´/í•œêµ­ì–´ ê° 6~8ê°œ ë¬¸ì¥ ë°°ì—´ (ìˆœì„œ ì¼ì¹˜, ê°ì • í­ë°œ ë¬˜ì‚¬)
3. cta_outro + cta_outro_ko: ì¼ë³¸ì–´/í•œêµ­ì–´ í˜‘ë°•ì„± êµ¬ë… ìœ ë„ ê° 1ë¬¸ì¥
4. pinned_comment: ë…¼ìŸ/ì„ íƒí˜• ëŒ“ê¸€ ìœ ë„ ì¼ë³¸ì–´ ì§ˆë¬¸ 1ê°œ
5. mood: "mystery" | "exciting" | "informative" ì¤‘ 1ê°œ (BGM ìë™ ë§¤ì¹­ìš©)
6. video_title: ê³µí¬/FOMOë¥¼ ìê·¹í•˜ëŠ” ê·¹ê°• ì–´ê·¸ë¡œ ì¼ë³¸ì–´ ì œëª© (ì˜ˆ: "ì¼ë³¸ì¸ 99%ê°€ ì†ê³  ìˆëŠ”..." ìŠ¤íƒ€ì¼)
7. hashtags: ì¼ë³¸ ì¡°íšŒìˆ˜ í„°ì§€ëŠ” í•´ì‹œíƒœê·¸ ì •í™•íˆ 5ê°œ (# í¬í•¨)
8. top5_info (ì£¼ì œê°€ ë­í‚¹/ë§›ì§‘/ëª…ì†Œì¼ ë•Œ í•„ìˆ˜): ì—…ì†Œ ì •ë³´ ë°°ì—´
   ê° í•­ëª©: {"rank": 1, "name_ko": "ê°€ê²Œëª…", "area": "ì§€ì—­êµ¬", "address_hint": "ì—­ ê·¼ì²˜ ë“± íŒíŠ¸", "desc_ko": "í•œì¤„ ì„¤ëª…", "desc_ja": "æ—¥æœ¬èªèª¬æ˜"}
9. bg_search_query: Pexels ë°°ê²½ì˜ìƒ ê²€ìƒ‰ìš© ì˜ì–´ í‚¤ì›Œë“œ (ì˜ˆ: "Seoul street food market night")

[ì¶œë ¥ í˜•ì‹ â€” ë°˜ë“œì‹œ ìˆœìˆ˜ JSONë§Œ ì¶œë ¥, ë§ˆí¬ë‹¤ìš´ ê¸ˆì§€]
{
  "topic_theme": "ì£¼ì œ í…Œë§ˆ",
  "video_title": "ê³µí¬/FOMO ê·¹ê°• ì–´ê·¸ë¡œ ì¼ë³¸ì–´ ì œëª©",
  "hashtags": ["#íƒœê·¸1","#íƒœê·¸2","#íƒœê·¸3","#íƒœê·¸4","#íƒœê·¸5"],
  "hook_3_sec": "ì¼ë³¸ì–´ í›… (ë¶€ì •ì  ê²½ê³  or ê°•í•œ ì˜ë¬¸ë¬¸)",
  "hook_3_sec_ko": "í•œêµ­ì–´ í›…",
  "body_script": ["ì¼ë³¸ì–´ ë¬¸ì¥1","ë¬¸ì¥2","..."],
  "body_script_ko": ["í•œêµ­ì–´ ë¬¸ì¥1","ë¬¸ì¥2","..."],
  "cta_outro": "ì¼ë³¸ì–´ í˜‘ë°•ì„± êµ¬ë… ìœ ë„",
  "cta_outro_ko": "í•œêµ­ì–´ í˜‘ë°•ì„± êµ¬ë… ìœ ë„",
  "pinned_comment": "ëŒ“ê¸€ í­ë°œ ìœ ë„ ë…¼ìŸ/ì„ íƒí˜• ì¼ë³¸ì–´ ì§ˆë¬¸",
  "mood": "mystery | exciting | informative ì¤‘ 1ê°œ",
  "bg_search_query": "pexels ê²€ìƒ‰ ì˜ì–´ í‚¤ì›Œë“œ",
  "top5_info": [
    {"rank":1,"name_ko":"ê°€ê²Œëª…","area":"ì§€ì—­","address_hint":"íŒíŠ¸","desc_ko":"í•œì¤„ì„¤ëª…","desc_ja":"æ—¥æœ¬èªèª¬æ˜"},
    ...
  ]
}"""


def generate_script_jp(
    config: AppConfig,
    extra_hint: str = "",
) -> Dict[str, Any]:
    """
    LLMì´ ì£¼ì œë¥¼ ìŠ¤ìŠ¤ë¡œ ì„ ì •í•´ ì¼ë³¸ì¸ íƒ€ê²Ÿ ìˆì¸  ëŒ€ë³¸ì„ JSONìœ¼ë¡œ ìƒì„±.
    extra_hint: ì¶”ê°€ë¡œ íŒíŠ¸ë¥¼ ì¤„ ë•Œ ì‚¬ìš© (ì˜ˆ: íŠ¹ì • ì§€ì—­, í‚¤ì›Œë“œ)
    """
    if not config.openai_api_key:
        raise RuntimeError("OPENAI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤.")

    theme_pool = "\n".join(f"- {t}" for t in JP_CONTENT_THEMES)
    user_text = (
        "ì•„ë˜ ì£¼ì œ í’€ì—ì„œ ì˜ê°ì„ ë°›ì•„, ì˜¤ëŠ˜ ê°€ì¥ ì¡°íšŒìˆ˜ê°€ í„°ì§ˆ ê²ƒ ê°™ì€ ì£¼ì œë¥¼ ìŠ¤ìŠ¤ë¡œ ì„ íƒí•˜ê±°ë‚˜ ìƒˆë¡œ ì°½ì‘í•˜ì„¸ìš”.\n\n"
        f"[ì£¼ì œ í’€ ì˜ˆì‹œ]\n{theme_pool}\n\n"
        + (f"[ì¶”ê°€ íŒíŠ¸]\n{extra_hint}\n\n" if extra_hint else "")
        + "ìœ„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì˜ ê·œì¹™ì„ ì™„ë²½íˆ ì§€ì¼œ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”."
    )

    client = OpenAI(api_key=config.openai_api_key)
    response = client.responses.create(
        model=config.openai_model,
        input=[
            {"role": "system", "content": JP_SHORTS_SYSTEM_PROMPT},
            {"role": "user", "content": user_text},
        ],
    )
    output_text = getattr(response, "output_text", "") or ""
    result = extract_json(output_text)
    if not result:
        raise RuntimeError("LLM JSON íŒŒì‹± ì‹¤íŒ¨")

    # í•´ì‹œíƒœê·¸ ì •ê·œí™”
    result["hashtags"] = normalize_hashtags(result.get("hashtags", []))
    # mood ê²€ì¦
    if result.get("mood") not in BGM_MOOD_CATEGORIES:
        result["mood"] = "exciting"
    # body_script ë¦¬ìŠ¤íŠ¸ í™•ì¸
    if not isinstance(result.get("body_script"), list):
        body = result.get("body_script", "")
        result["body_script"] = [s.strip() for s in str(body).split("ã€‚") if s.strip()]
    # body_script_ko fallback
    if not isinstance(result.get("body_script_ko"), list):
        result["body_script_ko"] = result["body_script"]  # ì¼ë³¸ì–´ ê·¸ëŒ€ë¡œ ë³µì‚¬ (ìµœí›„ fallback)
    # top5_info ê¸°ë³¸ê°’
    if not isinstance(result.get("top5_info"), list):
        result["top5_info"] = []
    # bg_search_query ê¸°ë³¸ê°’
    if not result.get("bg_search_query"):
        result["bg_search_query"] = "korea street city"
    return result


def _script_to_beats(script: Dict[str, Any]) -> List[str]:
    """generate_script_jp ê²°ê³¼ë¥¼ TTS/ì˜ìƒìš© í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜."""
    texts: List[str] = []
    hook = script.get("hook_3_sec", "")
    if hook:
        texts.append(hook)
    for line in script.get("body_script", []):
        if line:
            texts.append(line)
    outro = script.get("cta_outro", "")
    if outro:
        texts.append(outro)
    return texts


def match_bgm_by_mood(config: AppConfig, mood: str) -> Optional[str]:
    """
    mood(mystery/exciting/informative)ì— ë§ëŠ” BGM íŒŒì¼ ë°˜í™˜.
    1) assets/bgm/{mood}/ í´ë”ì—ì„œ ëœë¤ ì„ íƒ
    2) ì—†ìœ¼ë©´ Pixabayì—ì„œ ë‹¤ìš´ë¡œë“œ ì‹œë„
    3) ê·¸ë˜ë„ ì—†ìœ¼ë©´ ê¸°ì¡´ pick_bgm_path() fallback
    """
    mood_info = BGM_MOOD_CATEGORIES.get(mood, BGM_MOOD_CATEGORIES["exciting"])
    folder_name = mood_info["folder"]
    bgm_dir = os.path.join(config.assets_dir, "bgm", folder_name)
    os.makedirs(bgm_dir, exist_ok=True)

    # ê¸°ì¡´ íŒŒì¼ ìˆìœ¼ë©´ ëœë¤ ì„ íƒ
    existing = [
        os.path.join(bgm_dir, f)
        for f in os.listdir(bgm_dir)
        if f.lower().endswith((".mp3", ".wav", ".ogg", ".m4a"))
    ]
    if existing:
        return random.choice(existing)

    # Pixabay ë‹¤ìš´ë¡œë“œ ì‹œë„
    if config.pixabay_api_key:
        queries = mood_info.get("pixabay_queries", [])
        query = random.choice(queries) if queries else folder_name
        path = fetch_bgm_from_pixabay(config.pixabay_api_key, mood, bgm_dir, custom_query=query)
        if path:
            return path

    # fallback: pick_bgm_path (ê¸°ì¡´ í´ë”)
    existing_any = pick_bgm_path(config)
    if existing_any:
        return existing_any

    # ìµœí›„ fallback: numpyë¡œ ambient BGM ìë™ ìƒì„± (ì €ì‘ê¶Œ ì—†ìŒ)
    fallback_path = os.path.join(bgm_dir, f"generated_{mood}.wav")
    if not os.path.exists(fallback_path):
        try:
            _generate_bgm_fallback(fallback_path, duration=120.0, mood=mood)
        except Exception:
            return None
    return fallback_path if os.path.exists(fallback_path) else None


def pick_voice_id(voice_ids: List[str]) -> str:
    if not voice_ids:
        return ""
    return random.choice(voice_ids)


ALLOWED_REACTION_TAGS = [
    "shock",
    "wow",
    "laugh",
    "awkward",
    "facepalm",
    "angry",
    "cute",
    "plot",
    "ending",
]


def analyze_image_tags(
    config: AppConfig,
    image_path: str,
    allowed_tags: Optional[List[str]] = None,
) -> List[str]:
    if not config.openai_api_key:
        raise RuntimeError("OPENAI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤.")
    allowed_tags = allowed_tags or ALLOWED_REACTION_TAGS
    model = config.openai_vision_model or config.openai_model
    if not model:
        raise RuntimeError("OPENAI_VISION_MODEL ë˜ëŠ” OPENAI_MODELì´ ì—†ìŠµë‹ˆë‹¤.")
    if not os.path.exists(image_path):
        return []
    mime, _ = mimetypes.guess_type(image_path)
    if not mime:
        mime = "image/jpeg"
    with open(image_path, "rb") as file:
        b64 = base64.b64encode(file.read()).decode("utf-8")
    data_url = f"data:{mime};base64,{b64}"
    system_text = (
        "You are an expert Korean/Japanese internet meme and reaction image classifier. "
        "These images are used as reaction clips in short-form videos (Reels/Shorts/TikTok). "
        "Analyze the image carefully â€” look at facial expressions, body language, context, text overlays, and overall emotional tone. "
        "Choose 1-3 tags that best describe HOW this image would be used as a reaction in a video. "
        "Tag definitions:\n"
        "  shock: sudden surprise, jaw-drop, eyes wide open, disbelief\n"
        "  wow: amazement, impressed, mind-blown, spectacular\n"
        "  laugh: funny, humorous, comedic, lol expression\n"
        "  awkward: uncomfortable, embarrassed, cringe, nervous\n"
        "  facepalm: disappointment, 'seriously?', exasperation, headshake\n"
        "  angry: frustration, rage, upset, indignant\n"
        "  cute: adorable, heartwarming, sweet, lovely\n"
        "  plot: story setup, suspense, 'what happens next?', tension building\n"
        "  ending: conclusion, resolution, final reveal, outro moment\n"
        "Return JSON only: {\"tags\": [\"...\"], \"reason\": \"brief explanation\"}."
    )
    user_text = (
        f"Allowed tags: {', '.join(allowed_tags)}\n"
        "Look at this image and choose the most fitting reaction tags. "
        "Be precise â€” if the image shows sadness or crying, do NOT tag it as laugh. "
        "If it shows anger or frustration, use angry or facepalm. "
        "Match the actual emotional content of the image."
    )
    client = OpenAI(api_key=config.openai_api_key)
    response = client.responses.create(
        model=model,
        input=[
            {
                "role": "user",
                "content": [
                    {"type": "input_text", "text": user_text},
                    {"type": "input_image", "image_url": data_url},
                ],
            }
        ],
    )
    output_text = getattr(response, "output_text", "") or ""
    result = extract_json(output_text)
    tags = result.get("tags", []) if isinstance(result, dict) else []
    cleaned = []
    for tag in tags:
        if isinstance(tag, str):
            value = tag.strip().lower()
            if value in allowed_tags:
                cleaned.append(value)
    return list(dict.fromkeys(cleaned))


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# NEW: ì—ì…‹ ì´ë¯¸ì§€ â†’ ì½˜í…ì¸  ì¹´í…Œê³ ë¦¬ ë¶„ì„
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def analyze_image_content_category(
    config: AppConfig,
    image_path: str,
) -> str:
    """
    ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•´ì„œ CONTENT_CATEGORIES ì¤‘ ê°€ì¥ ì˜ ì–´ìš¸ë¦¬ëŠ” ì¹´í…Œê³ ë¦¬ ë°˜í™˜.
    ê¸°ì¡´ analyze_image_tagsì™€ ë³„ë„ë¡œ ì¹´í…Œê³ ë¦¬ ë ˆë²¨ ë¶„ë¥˜.
    """
    if not config.openai_api_key:
        return "humor"
    model = config.openai_vision_model or config.openai_model
    if not os.path.exists(image_path):
        return "humor"
    mime, _ = mimetypes.guess_type(image_path)
    if not mime:
        mime = "image/jpeg"
    with open(image_path, "rb") as file:
        b64 = base64.b64encode(file.read()).decode("utf-8")
    data_url = f"data:{mime};base64,{b64}"
    system_text = (
        "You are an expert Korean/Japanese internet meme and reaction image classifier "
        "for short-form video content (Reels/Shorts/TikTok). "
        "Analyze the image carefully â€” facial expressions, body language, context clues, text overlays, color tone, and overall emotional atmosphere. "
        "Pick the single most fitting category based on the ACTUAL emotional content of the image.\n\n"
        "Category definitions (choose ONE):\n"
        "  humor       â€” funny, comedic, joke, silly, meme with punchline\n"
        "  touching    â€” emotional, tearful, moving story, heartfelt, makes you cry\n"
        "  shocking    â€” jaw-dropping reveal, plot twist, unbelievable fact, WTF moment\n"
        "  heartwarming â€” wholesome, warm fuzzy feeling, acts of kindness, family/pet love\n"
        "  cringe      â€” awkward, embarrassing, secondhand embarrassment, 'why would they do that'\n"
        "  exciting    â€” hype, energetic, celebration, victory, pumped up\n"
        "  sad         â€” grief, loss, lonely, crying, melancholy, unfortunate situation\n"
        "  anger       â€” frustration, injustice, rant, outrage, 'this is wrong'\n\n"
        "IMPORTANT: Do not default to 'humor'. Carefully examine what emotion the image actually conveys. "
        "A crying person = sad or touching, NOT humor. An angry face = anger, NOT humor. "
        "Return JSON only: {\"category\": \"one_of_the_above\", \"reason\": \"brief_explanation\"}"
    )
    user_text = (
        "Classify this image into exactly one category based on its actual emotional content. "
        "Look carefully at expressions, context, and atmosphere. "
        "Do NOT assume it is humor just because it's a meme format."
    )
    try:
        client = OpenAI(api_key=config.openai_api_key)
        response = client.responses.create(
            model=model,
            input=[
                {
                    "role": "user",
                    "content": [
                        {"type": "input_text", "text": system_text},
                        {"type": "input_image", "image_url": data_url},
                        {"type": "input_text", "text": user_text},
                    ],
                }
            ],
        )
        output_text = getattr(response, "output_text", "") or ""
        result = extract_json(output_text)
        category = result.get("category", "").strip().lower()
        if category in CONTENT_CATEGORIES:
            return category
        # ìœ ì‚¬ ë‹¨ì–´ ë§¤í•‘ (ëª¨ë¸ì´ ê°€ë” ë¹„ìŠ·í•œ ë‹¨ì–´ë¡œ ë°˜í™˜í•  ë•Œ)
        fallback_map = {
            "funny": "humor", "comedy": "humor", "comic": "humor",
            "emotional": "touching", "heartfelt": "touching", "cry": "touching",
            "crying": "sad", "grief": "sad", "melancholy": "sad",
            "wholesome": "heartwarming", "warm": "heartwarming", "sweet": "heartwarming",
            "twist": "shocking", "reveal": "shocking", "wtf": "shocking",
            "awkward": "cringe", "embarrass": "cringe",
            "hype": "exciting", "energy": "exciting", "celebration": "exciting",
            "angry": "anger", "rage": "anger", "frustrat": "anger",
        }
        for key, mapped in fallback_map.items():
            if key in category:
                return mapped
    except Exception:
        pass
    return "humor"


def tts_openai(
    config: AppConfig,
    text: str,
    output_path: str,
    voice: str,
) -> str:
    if not config.openai_api_key:
        raise RuntimeError("OPENAI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤.")
    if not voice:
        voice = "alloy"
    headers = {
        "Authorization": f"Bearer {config.openai_api_key}",
        "Content-Type": "application/json",
    }
    payload = {
        "model": config.openai_tts_model,
        "input": text,
        "voice": voice,
    }
    response = requests.post(
        "https://api.openai.com/v1/audio/speech",
        json=payload,
        headers=headers,
        timeout=120,
    )
    response.raise_for_status()
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    with open(output_path, "wb") as file:
        file.write(response.content)
    return output_path


@dataclass
class AssetItem:
    asset_id: str
    path: str
    tags: List[str]
    kind: str


def ensure_dirs(paths: List[str]) -> None:
    for path in paths:
        os.makedirs(path, exist_ok=True)


def load_manifest(manifest_path: str) -> List[AssetItem]:
    if not os.path.exists(manifest_path):
        return []
    with open(manifest_path, "r", encoding="utf-8") as file:
        raw = json.load(file)
    return [
        AssetItem(
            asset_id=item["asset_id"],
            path=item["path"],
            tags=item.get("tags", []),
            kind=item.get("kind", "image"),
        )
        for item in raw
    ]


def save_manifest(manifest_path: str, items: List[AssetItem]) -> None:
    with open(manifest_path, "w", encoding="utf-8") as file:
        json.dump([item.__dict__ for item in items], file, ensure_ascii=False, indent=2)


def add_asset(
    manifest_path: str,
    asset_path: str,
    tags: List[str],
    kind: str = "image",
) -> AssetItem:
    items = load_manifest(manifest_path)
    asset_id = f"asset_{len(items)+1:04d}"
    new_item = AssetItem(asset_id=asset_id, path=asset_path, tags=tags, kind=kind)
    items.append(new_item)
    save_manifest(manifest_path, items)
    return new_item


def update_asset_tags(
    manifest_path: str,
    tag_map: Dict[str, List[str]],
    keep_existing: bool = True,
) -> int:
    if not tag_map:
        return 0
    items = load_manifest(manifest_path)
    updated = 0
    for item in items:
        if item.asset_id not in tag_map:
            continue
        new_tags = tag_map[item.asset_id]
        if keep_existing:
            merged = list(dict.fromkeys(item.tags + new_tags))
            item.tags = merged
        else:
            item.tags = list(dict.fromkeys(new_tags))
        updated += 1
    if updated:
        save_manifest(manifest_path, items)
    return updated


def remove_assets(
    manifest_path: str,
    asset_ids: List[str],
    delete_files: bool = False,
) -> int:
    if not asset_ids:
        return 0
    items = load_manifest(manifest_path)
    remaining: List[AssetItem] = []
    removed = 0
    remove_set = set(asset_ids)
    for item in items:
        if item.asset_id in remove_set:
            removed += 1
            if delete_files and os.path.exists(item.path):
                try:
                    os.remove(item.path)
                except Exception:
                    pass
        else:
            remaining.append(item)
    if removed:
        save_manifest(manifest_path, remaining)
    return removed


def list_tags(items: List[AssetItem]) -> List[str]:
    tags: List[str] = []
    for item in items:
        for tag in item.tags:
            if tag not in tags:
                tags.append(tag)
    return tags


def filter_assets_by_tags(items: List[AssetItem], tags: List[str]) -> List[AssetItem]:
    if not tags:
        return items
    tag_set = set(tags)
    return [item for item in items if tag_set.intersection(set(item.tags))]


def pick_asset(items: List[AssetItem], tags: List[str]) -> Optional[AssetItem]:
    candidates = filter_assets_by_tags(items, tags)
    if not candidates:
        return random.choice(items) if items else None
    return random.choice(candidates)


def pick_asset_by_category(items: List[AssetItem], category: str) -> Optional[AssetItem]:
    """ì½˜í…ì¸  ì¹´í…Œê³ ë¦¬ì— ë§ëŠ” ì—ì…‹ ì„ íƒ (ì¹´í…Œê³ ë¦¬ íƒœê·¸ í¬í•¨ ìš°ì„ )."""
    # ì¹´í…Œê³ ë¦¬ ìì²´ê°€ íƒœê·¸ë¡œ ì €ì¥ëœ ì—ì…‹ ìš°ì„ 
    category_candidates = [item for item in items if category in item.tags]
    if category_candidates:
        return random.choice(category_candidates)
    # ì¹´í…Œê³ ë¦¬â†’ì—ì…‹íƒœê·¸ ë§¤í•‘ìœ¼ë¡œ fallback
    mapped_tags = CATEGORY_TO_ASSET_TAGS.get(category, [])
    if mapped_tags:
        return pick_asset(items, mapped_tags)
    return random.choice(items) if items else None


def tags_from_text(text: str) -> List[str]:
    parts = [part.strip() for part in text.split(",")]
    return [part for part in parts if part]


def _load_font(font_path: str, size: int) -> ImageFont.FreeTypeFont:
    if not MOVIEPY_AVAILABLE:
        raise RuntimeError(f"MoviePy/PIL not available: {MOVIEPY_ERROR}")
    if font_path and os.path.exists(font_path):
        return ImageFont.truetype(font_path, size=size)
    return ImageFont.load_default()


def _fit_image_to_canvas(image: Image.Image, size: Tuple[int, int]) -> Image.Image:
    if not MOVIEPY_AVAILABLE:
        raise RuntimeError(f"MoviePy/PIL not available: {MOVIEPY_ERROR}")
    target_width, target_height = size
    original_width, original_height = image.size
    scale = max(target_width / original_width, target_height / original_height)
    new_width = int(original_width * scale)
    new_height = int(original_height * scale)
    resized = image.resize((new_width, new_height), Image.LANCZOS)
    left = (new_width - target_width) // 2
    top = (new_height - target_height) // 2
    return resized.crop((left, top, left + target_width, top + target_height))


def _make_background(image: Image.Image, size: Tuple[int, int]) -> Image.Image:
    if not MOVIEPY_AVAILABLE:
        raise RuntimeError(f"MoviePy/PIL not available: {MOVIEPY_ERROR}")
    background = image.resize(size, Image.LANCZOS)
    return background.filter(ImageFilter.GaussianBlur(radius=18))


def _wrap_cjk_text(text: str, max_width_px: int, font_size: int) -> List[str]:
    """CJK(ì¼ë³¸ì–´Â·í•œêµ­ì–´) ë¬¸ìë¥¼ í”½ì…€ í­ ê¸°ì¤€ìœ¼ë¡œ ì¤„ë°”ê¿ˆ."""
    # ì˜ë¬¸ì€ ~0.55ë°°, CJKëŠ” ~1ë°° í­ ì°¨ì§€
    def char_w(c: str) -> float:
        return 1.0 if ord(c) > 127 else 0.55

    max_chars = max(6, int(max_width_px / (font_size * 0.95)))
    lines: List[str] = []
    current = ""
    current_w = 0.0
    for ch in text:
        cw = char_w(ch)
        if current_w + cw > max_chars:
            lines.append(current)
            current = ch
            current_w = cw
        else:
            current += ch
            current_w += cw
    if current:
        lines.append(current)
    return lines or [text]


def _draw_subtitle(
    image: Image.Image,
    text: str,
    font_path: str,
    canvas_width: int,
    canvas_height: int,
) -> Image.Image:
    """í™”ë©´ í•˜ë‹¨ ìë§‰ ì˜ì—­ì— ë°˜íˆ¬ëª… ë°°ê²½ + í°ìƒ‰ í…Œë‘ë¦¬ í…ìŠ¤íŠ¸ë¥¼ ê·¸ë¦½ë‹ˆë‹¤."""
    if not MOVIEPY_AVAILABLE:
        raise RuntimeError(f"MoviePy/PIL not available: {MOVIEPY_ERROR}")
    font_size = max(48, canvas_width // 18)
    font = _load_font(font_path, font_size)
    pad_x = int(canvas_width * 0.05)
    max_text_w = canvas_width - pad_x * 2
    lines = _wrap_cjk_text(text, max_text_w, font_size)
    line_h = font_size + 10
    total_h = line_h * len(lines) + 20
    box_y = canvas_height - total_h - 80
    # ë°˜íˆ¬ëª… ë°°ê²½ ë°•ìŠ¤
    overlay = Image.new("RGBA", image.size, (0, 0, 0, 0))
    box_draw = ImageDraw.Draw(overlay)
    box_draw.rectangle(
        [pad_x - 20, box_y - 10, canvas_width - pad_x + 20, canvas_height - 60],
        fill=(0, 0, 0, 160),
    )
    image = Image.alpha_composite(image.convert("RGBA"), overlay).convert("RGB")
    draw = ImageDraw.Draw(image)
    y = box_y
    for line in lines:
        try:
            lw = font.getbbox(line)[2]
        except Exception:
            lw = len(line) * font_size
        lx = max(pad_x, (canvas_width - lw) // 2)
        draw.text((lx, y), line, font=font, fill=(255, 255, 255),
                  stroke_width=3, stroke_fill=(0, 0, 0))
        y += line_h
    return image


def _overlay_sticker(
    image: Image.Image,
    asset_path: str,
    canvas_width: int,
    canvas_height: int,
    size: int = 220,
) -> Image.Image:
    """ì—ì…‹ ì´ë¯¸ì§€ë¥¼ ì´ëª¨í‹°ì½˜ì²˜ëŸ¼ ìš°í•˜ë‹¨ì— ì‘ê²Œ ë¶™ì…ë‹ˆë‹¤."""
    if not os.path.exists(asset_path):
        return image
    try:
        sticker = Image.open(asset_path).convert("RGBA")
        sticker = sticker.resize((size, size), Image.LANCZOS)
        margin = 40
        x = canvas_width - size - margin
        y = canvas_height - size - 200  # ìë§‰ ìœ„
        base = image.convert("RGBA")
        base.paste(sticker, (x, y), sticker)
        return base.convert("RGB")
    except Exception:
        return image


def _compose_frame(
    asset_path: str,
    text: str,
    size: Tuple[int, int],
    font_path: str,
) -> Image.Image:
    """ì •ì  ì´ë¯¸ì§€ ë°°ê²½ í”„ë ˆì„ ìƒì„± (ë°°ê²½ì˜ìƒ ì—†ì„ ë•Œ fallback)."""
    if not MOVIEPY_AVAILABLE:
        raise RuntimeError(f"MoviePy/PIL not available: {MOVIEPY_ERROR}")
    base = Image.open(asset_path).convert("RGB")
    background = _make_background(base, size)
    composed = background.copy()
    width, height = size
    composed = _draw_subtitle(composed, text, font_path, width, height)
    composed = _overlay_sticker(composed, asset_path, width, height, size=200)
    return composed


def fetch_pexels_video(
    query: str,
    api_key: str,
    output_dir: str,
    canvas_w: int = 1080,
    canvas_h: int = 1920,
) -> Optional[str]:
    """Pexelsì—ì„œ ì„¸ë¡œí˜•(portrait) royalty-free ì˜ìƒì„ ê²€ìƒ‰Â·ë‹¤ìš´ë¡œë“œ."""
    if not api_key:
        return None
    os.makedirs(output_dir, exist_ok=True)
    try:
        headers = {"Authorization": api_key}
        params = {"query": query, "per_page": 15, "orientation": "portrait"}
        resp = requests.get(
            "https://api.pexels.com/videos/search",
            headers=headers,
            params=params,
            timeout=30,
        )
        resp.raise_for_status()
        videos = resp.json().get("videos", [])
        random.shuffle(videos)
        for video in videos[:8]:
            files = sorted(
                video.get("video_files", []),
                key=lambda f: abs(f.get("width", 0) - canvas_w),
            )
            for vf in files:
                link = vf.get("link", "")
                if not link:
                    continue
                try:
                    vresp = requests.get(link, stream=True, timeout=120)
                    vresp.raise_for_status()
                    fname = f"bg_{random.randint(100000, 999999)}.mp4"
                    fpath = os.path.join(output_dir, fname)
                    with open(fpath, "wb") as vf_out:
                        for chunk in vresp.iter_content(chunk_size=65536):
                            vf_out.write(chunk)
                    return fpath
                except Exception:
                    continue
    except Exception:
        pass
    return None


def _generate_bgm_fallback(output_path: str, duration: float, mood: str) -> str:
    """
    Pixabay API í‚¤Â·ë¡œì»¬ íŒŒì¼ ì—†ì„ ë•Œ numpyë¡œ ê°„ë‹¨í•œ ambient ë°°ê²½ìŒ ìƒì„±.
    ë‹¨ìˆœ ì‚¬ì¸íŒŒ í™”ìŒ â€” ì €ì‘ê¶Œ ì—†ìŒ.
    """
    import wave
    import struct
    import math

    sample_rate = 44100
    n = int(duration * sample_rate)
    mood_chords: Dict[str, List[float]] = {
        "mystery":     [110.0, 146.8, 164.8],   # Am chord drone
        "exciting":    [220.0, 277.2, 329.6],   # C major bright
        "informative": [196.0, 246.9, 293.7],   # G major mellow
    }
    freqs = mood_chords.get(mood, mood_chords["exciting"])
    samples: List[int] = []
    for i in range(n):
        t = i / sample_rate
        fade = min(t / 1.5, 1.0, (duration - t) / 1.5)
        # LFOë¡œ ì‚´ì§ ë³€ë™ê°
        lfo = 1 + 0.008 * math.sin(2 * math.pi * 0.3 * t)
        val = sum(math.sin(2 * math.pi * f * lfo * t) for f in freqs)
        val = val / len(freqs) * 0.18 * fade
        samples.append(max(-32767, min(32767, int(val * 32767))))
    os.makedirs(os.path.dirname(output_path) or ".", exist_ok=True)
    with wave.open(output_path, "w") as wf:
        wf.setnchannels(1)
        wf.setsampwidth(2)
        wf.setframerate(sample_rate)
        wf.writeframes(struct.pack(f"<{len(samples)}h", *samples))
    return output_path


def _estimate_durations(texts: List[str], total_duration: float) -> List[float]:
    lengths = [max(len(text), 1) for text in texts]
    total = sum(lengths)
    raw = [(length / total) * total_duration for length in lengths]
    minimum = 1.2
    adjusted = [max(duration, minimum) for duration in raw]
    scale = total_duration / sum(adjusted)
    return [duration * scale for duration in adjusted]


def render_video(
    config: AppConfig,
    asset_paths: List[str],
    texts: List[str],
    tts_audio_path: str,
    output_path: str,
    bgm_path: str | None = None,
    bgm_volume: float = 0.08,
    bg_video_path: str | None = None,
) -> str:
    """
    TTS + ìë§‰ + ì—ì…‹ ìŠ¤í‹°ì»¤ + ë°°ê²½ì˜ìƒ(or ì •ì  ì´ë¯¸ì§€)ìœ¼ë¡œ ìˆì¸  ì˜ìƒ ìƒì„±.
    bg_video_pathê°€ ìˆìœ¼ë©´ ì˜ìƒ ë°°ê²½, ì—†ìœ¼ë©´ ì •ì  ì´ë¯¸ì§€ ë°°ê²½ ì‚¬ìš©.
    """
    if not MOVIEPY_AVAILABLE:
        raise RuntimeError(f"MoviePy/PIL not available: {MOVIEPY_ERROR}")
    W, H = config.width, config.height
    audio_clip = AudioFileClip(tts_audio_path)
    durations = _estimate_durations(texts, audio_clip.duration)
    clips = []

    bg_vid = None
    if bg_video_path and os.path.exists(bg_video_path):
        try:
            bg_vid = VideoFileClip(bg_video_path).without_audio()
            # ì„¸ë¡œí˜•ìœ¼ë¡œ resize (ë¹„ìœ¨ ìœ ì§€ â†’ crop)
            bw, bh = bg_vid.size
            scale = max(W / bw, H / bh)
            bg_vid = bg_vid.resize((int(bw * scale), int(bh * scale)))
            cx = (bg_vid.size[0] - W) // 2
            cy = (bg_vid.size[1] - H) // 2
            bg_vid = bg_vid.crop(x1=cx, y1=cy, x2=cx + W, y2=cy + H)
        except Exception:
            bg_vid = None

    vid_offset = 0.0
    for index, text in enumerate(texts):
        asset_path = asset_paths[min(index, len(asset_paths) - 1)]
        dur = durations[index]

        if bg_vid is not None:
            # ë°°ê²½ ì˜ìƒì—ì„œ ëœë¤ ì˜¤í”„ì…‹ êµ¬ê°„ ì¶”ì¶œ
            max_start = max(bg_vid.duration - dur - 0.1, 0)
            seg_start = random.uniform(0, max_start) if max_start > 0 else 0
            seg = bg_vid.subclip(seg_start, seg_start + dur)

            # í´ë¡œì € ìº¡ì²˜ (Python for-loop ìº¡ì²˜ ì´ìŠˆ ë°©ì§€)
            _text = text
            _asset = asset_path
            _font = config.font_path

            def _make_frame(frame, __text=_text, __asset=_asset, __font=_font):
                img = Image.fromarray(frame).convert("RGB")
                img = _draw_subtitle(img, __text, __font, W, H)
                img = _overlay_sticker(img, __asset, W, H, size=200)
                return np.array(img)

            clip = seg.fl_image(_make_frame).set_duration(dur)
        else:
            # fallback: ì •ì  ì´ë¯¸ì§€ ë°°ê²½
            frame_img = _compose_frame(asset_path, text, (W, H), config.font_path)
            clip = ImageClip(np.array(frame_img)).set_duration(dur)
            clip = clip.fx(vfx.resize, lambda t, d=dur: 1 + 0.02 * (t / max(d, 0.1)))

        clips.append(clip)
        vid_offset += dur

    if bg_vid:
        bg_vid.close()

    video = concatenate_videoclips(clips, method="compose").set_fps(config.fps)

    # BGM ì²˜ë¦¬
    if bgm_path and os.path.exists(bgm_path):
        bgm_clip = AudioFileClip(bgm_path).volumex(bgm_volume)
        if bgm_clip.duration < audio_clip.duration:
            bgm_clip = bgm_clip.loop(duration=audio_clip.duration)
        bgm_clip = bgm_clip.set_duration(audio_clip.duration)
        audio = CompositeAudioClip([audio_clip, bgm_clip])
    else:
        audio = audio_clip

    video = video.set_audio(audio)
    os.makedirs(os.path.dirname(output_path) or ".", exist_ok=True)
    video.write_videofile(
        output_path,
        codec="libx264",
        audio_codec="aac",
        fps=config.fps,
        threads=4,
        logger=None,
    )
    audio_clip.close()
    video.close()
    return output_path


def _list_audio_files(path: str) -> List[str]:
    if not os.path.exists(path):
        return []
    items = []
    for name in os.listdir(path):
        if name.lower().endswith((".mp3", ".wav", ".m4a", ".aac", ".ogg")):
            items.append(os.path.join(path, name))
    return items


def pick_bgm_path(config: AppConfig) -> Optional[str]:
    mode = (config.bgm_mode or "off").lower().strip()
    if mode in {"", "off", "none"}:
        return None
    bgm_dir = os.path.join(config.assets_dir, "bgm")
    trending_dir = os.path.join(bgm_dir, "trending")
    trending = _list_audio_files(trending_dir)
    normal = _list_audio_files(bgm_dir)
    if mode in {"trend", "trending"}:
        pool = trending or normal
    elif mode in {"random", "auto"}:
        pool = trending + normal if trending else normal
    else:
        pool = normal
    if not pool:
        return None
    return random.choice(pool)


def append_publish_log(config: AppConfig, row: Dict[str, str]) -> None:
    if not config.sheet_id:
        raise RuntimeError("SHEET_IDê°€ ì—†ìŠµë‹ˆë‹¤.")
    if not config.google_service_account_json:
        raise RuntimeError("GOOGLE_SERVICE_ACCOUNT_JSONì´ ì—†ìŠµë‹ˆë‹¤.")
    client = gspread.service_account_from_dict(config.google_service_account_json)
    sheet = client.open_by_key(config.sheet_id)
    try:
        worksheet = sheet.worksheet("publish_log")
    except Exception:
        worksheet = sheet.add_worksheet(title="publish_log", rows=1000, cols=20)
    headers = [
        "date_jst",
        "title_ja",
        "hashtags_ja",
        "template_id",
        "asset_ids",
        "voice_id",
        "video_path",
        "youtube_video_id",
        "youtube_url",
        "status",
        "error",
    ]
    existing = worksheet.row_values(1)
    if existing != headers:
        worksheet.update("A1", [headers])
    values: List[str] = [row.get(header, "") for header in headers]
    worksheet.append_row(values, value_input_option="USER_ENTERED")


def upload_video(
    config: AppConfig,
    file_path: str,
    title: str,
    description: str,
    tags: Optional[list] = None,
) -> Dict[str, str]:
    if not config.youtube_client_id or not config.youtube_client_secret or not config.youtube_refresh_token:
        raise RuntimeError("YouTube OAuth ì„¤ì •ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
    credentials = Credentials(
        token=None,
        refresh_token=config.youtube_refresh_token,
        token_uri="https://oauth2.googleapis.com/token",
        client_id=config.youtube_client_id,
        client_secret=config.youtube_client_secret,
        scopes=["https://www.googleapis.com/auth/youtube.upload"],
    )
    youtube = build("youtube", "v3", credentials=credentials)
    body = {
        "snippet": {
            "title": title,
            "description": description,
            "tags": tags or [],
            "categoryId": "24",
        },
        "status": {"privacyStatus": config.youtube_privacy_status},
    }
    media = MediaFileUpload(file_path, chunksize=-1, resumable=True)
    request = youtube.videos().insert(part="snippet,status", body=body, media_body=media)
    response = request.execute()
    video_id = response.get("id", "")
    return {"video_id": video_id, "video_url": f"https://www.youtube.com/watch?v={video_id}"}


def build_google_oauth_url(
    client_id: str,
    redirect_uri: str,
    scope: str,
    prompt_consent: bool = True,
) -> str:
    params = {
        "client_id": client_id,
        "redirect_uri": redirect_uri,
        "response_type": "code",
        "scope": scope,
        "access_type": "offline",
        "include_granted_scopes": "true",
    }
    if prompt_consent:
        params["prompt"] = "consent"
    return "https://accounts.google.com/o/oauth2/v2/auth?" + urlencode(params)


def exchange_oauth_code_for_token(
    client_id: str,
    client_secret: str,
    code: str,
    redirect_uri: str,
) -> Dict[str, Any]:
    data = {
        "code": code,
        "client_id": client_id,
        "client_secret": client_secret,
        "redirect_uri": redirect_uri,
        "grant_type": "authorization_code",
    }
    response = requests.post("https://oauth2.googleapis.com/token", data=data, timeout=30)
    response.raise_for_status()
    return response.json()


def collect_images_serpapi(
    query: str,
    api_key: str,
    output_dir: str,
    limit: int = 12,
) -> List[str]:
    if not query or not query.strip():
        raise RuntimeError("ê²€ìƒ‰ì–´ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
    if not api_key:
        raise RuntimeError("SERPAPI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤.")
    os.makedirs(output_dir, exist_ok=True)
    params = {
        "engine": "google_images",
        "q": query,
        "api_key": api_key,
        "ijn": 0,
        "num": min(limit, 20),
    }
    response = requests.get("https://serpapi.com/search.json", params=params, timeout=60)
    response.raise_for_status()
    results = response.json().get("images_results", [])
    downloaded: List[str] = []
    for item in results[:limit]:
        image_url = item.get("original") or item.get("thumbnail")
        if not image_url:
            continue
        try:
            image_response = requests.get(image_url, timeout=30)
            image_response.raise_for_status()
            filename = f"{random.randint(100000, 999999)}.jpg"
            file_path = os.path.join(output_dir, filename)
            with open(file_path, "wb") as file:
                file.write(image_response.content)
            downloaded.append(file_path)
        except Exception:
            continue
    return downloaded


def get_trend_context(config: AppConfig) -> str:
    if not config.serpapi_api_key:
        return ""
    try:
        params = {
            "engine": "google_news",
            "q": "æ—¥æœ¬ ãƒˆãƒ¬ãƒ³ãƒ‰ ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°",
            "api_key": config.serpapi_api_key,
            "hl": "ja",
            "gl": "jp",
        }
        response = requests.get("https://serpapi.com/search.json", params=params, timeout=60)
        response.raise_for_status()
        news = response.json().get("news_results", [])[:8]
        titles = [item.get("title", "") for item in news if item.get("title")]
        if not titles:
            return ""
        return " / ".join(titles)
    except Exception:
        return ""


def generate_trend_queries(config: AppConfig, trend_context: str, count: int = 4) -> List[str]:
    if not trend_context or not config.openai_api_key:
        return []
    system_text = (
        "You generate short Japanese search queries for image search. "
        "Return JSON only. Format: {\"queries\": [\"...\"]}."
    )
    user_text = (
        f"Trend context (Japan): {trend_context}\n"
        f"Create {count} short Japanese image-search queries suitable for short-form content visuals. "
        "Avoid brand names if possible. Keep each query under 6 words."
    )
    try:
        client = OpenAI(api_key=config.openai_api_key)
        response = client.responses.create(
            model=config.openai_model,
            input=[
                {"role": "system", "content": system_text},
                {"role": "user", "content": user_text},
            ],
        )
        output_text = getattr(response, "output_text", "") or ""
        result = extract_json(output_text)
        queries = result.get("queries", []) if isinstance(result, dict) else []
        cleaned: List[str] = []
        for query in queries:
            if isinstance(query, str):
                value = query.strip()
                if value:
                    cleaned.append(value)
        if cleaned:
            return cleaned[:count]
    except Exception:
        return []
    return []


def collect_images_pexels(
    query: str,
    api_key: str,
    output_dir: str,
    limit: int = 12,
    locale: str = "ja-JP",
) -> List[str]:
    if not api_key:
        raise RuntimeError("PEXELS_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤.")
    os.makedirs(output_dir, exist_ok=True)
    headers = {"Authorization": api_key}
    params = {
        "query": query,
        "per_page": min(limit, 80),
        "orientation": "portrait",
        "locale": locale,
    }
    response = requests.get("https://api.pexels.com/v1/search", params=params, headers=headers, timeout=60)
    response.raise_for_status()
    photos = response.json().get("photos", [])
    downloaded: List[str] = []
    for photo in photos:
        src = photo.get("src", {}) if isinstance(photo, dict) else {}
        image_url = src.get("large") or src.get("original")
        if not image_url:
            continue
        try:
            image_response = requests.get(image_url, timeout=30)
            image_response.raise_for_status()
            filename = f"{random.randint(100000, 999999)}.jpg"
            file_path = os.path.join(output_dir, filename)
            with open(file_path, "wb") as file:
                file.write(image_response.content)
            downloaded.append(file_path)
            if len(downloaded) >= limit:
                break
        except Exception:
            continue
    return downloaded


def collect_images_auto_trend(
    config: AppConfig,
    output_dir: str,
    total_count: int = 12,
    max_queries: int = 4,
) -> Tuple[List[str], List[str]]:
    trend_context = get_trend_context(config)
    queries = generate_trend_queries(config, trend_context, count=max_queries)
    if not queries:
        raise RuntimeError("íŠ¸ë Œë“œ ê²€ìƒ‰ì–´ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. SERPAPI_API_KEYë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    if not config.pexels_api_key:
        raise RuntimeError("PEXELS_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤.")
    os.makedirs(output_dir, exist_ok=True)
    collected: List[str] = []
    remaining = total_count
    for query in queries:
        if remaining <= 0:
            break
        per_query = max(1, min(remaining, total_count // max(1, len(queries))))
        items = collect_images_pexels(
            query=query,
            api_key=config.pexels_api_key,
            output_dir=output_dir,
            limit=per_query,
            locale="ja-JP",
        )
        collected.extend(items)
        remaining = total_count - len(collected)
    return collected[:total_count], queries


def send_telegram_message(token: str, chat_id: str, text: str) -> bool:
    """
    í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ì „ì†¡. ì„±ê³µí•˜ë©´ True, ì‹¤íŒ¨í•˜ë©´ False ë°˜í™˜.
    - 4096ì ì´ˆê³¼ ì‹œ ìë™ ë¶„í•  ì „ì†¡
    - parse_mode ë¯¸ì‚¬ìš© (í•´ì‹œíƒœê·¸/íŠ¹ìˆ˜ë¬¸ì ì˜¤ë¥˜ ë°©ì§€)
    """
    if not token or not chat_id:
        return False
    url = f"https://api.telegram.org/bot{token}/sendMessage"
    max_len = 4000
    chunks = [text[i : i + max_len] for i in range(0, max(len(text), 1), max_len)]
    success = True
    for chunk in chunks:
        payload = {"chat_id": chat_id, "text": chunk}
        try:
            resp = requests.post(url, json=payload, timeout=30)
            if not resp.ok:
                print(f"[Telegram ì „ì†¡ ì‹¤íŒ¨] status={resp.status_code} body={resp.text[:300]}")
                success = False
        except Exception as exc:
            print(f"[Telegram ì „ì†¡ ì˜¤ë¥˜] {exc}")
            success = False
    return success


def send_telegram_approval_request(
    token: str,
    chat_id: str,
    text: str,
) -> Optional[str]:
    """
    ì¸ë¼ì¸ ë²„íŠ¼(âœ… ìŠ¹ì¸ / ğŸ”„ êµí™˜)ì´ í¬í•¨ëœ ìŠ¹ì¸ ìš”ì²­ ë©”ì‹œì§€ ì „ì†¡.
    ì„±ê³µ ì‹œ message_id ë°˜í™˜, ì‹¤íŒ¨ ì‹œ None ë°˜í™˜.
    """
    if not token or not chat_id:
        return None
    url = f"https://api.telegram.org/bot{token}/sendMessage"
    max_len = 3800  # ë²„íŠ¼ í¬í•¨ ì—¬ìœ  í™•ë³´
    body = text[:max_len] + ("..." if len(text) > max_len else "")
    payload = {
        "chat_id": chat_id,
        "text": body,
        "reply_markup": {
            "inline_keyboard": [
                [
                    {"text": "âœ… ìŠ¹ì¸", "callback_data": "approve"},
                    {"text": "ğŸ”„ êµí™˜", "callback_data": "swap"},
                ]
            ]
        },
    }
    try:
        resp = requests.post(url, json=payload, timeout=30)
        if resp.ok:
            return str(resp.json().get("result", {}).get("message_id", ""))
        print(f"[Telegram ë²„íŠ¼ ì „ì†¡ ì‹¤íŒ¨] status={resp.status_code} body={resp.text[:300]}")
    except Exception as exc:
        print(f"[Telegram ë²„íŠ¼ ì „ì†¡ ì˜¤ë¥˜] {exc}")
    return None


def _answer_callback_query(token: str, callback_query_id: str, text: str = "") -> None:
    """ë²„íŠ¼ í´ë¦­ í›„ ë¡œë”© ìŠ¤í”¼ë„ˆ ì œê±° (answerCallbackQuery)."""
    try:
        requests.post(
            f"https://api.telegram.org/bot{token}/answerCallbackQuery",
            json={"callback_query_id": callback_query_id, "text": text},
            timeout=10,
        )
    except Exception:
        pass


def _disable_approval_buttons(token: str, chat_id: str, message_id: str, result: str) -> None:
    """ë²„íŠ¼ í´ë¦­ í›„ ë©”ì‹œì§€ë¥¼ ê²°ê³¼ í…ìŠ¤íŠ¸ë¡œ êµì²´í•´ ë²„íŠ¼ ë¹„í™œì„±í™”."""
    label = "âœ… ìŠ¹ì¸ë¨" if result == "approve" else "ğŸ”„ êµí™˜ë¨"
    try:
        requests.post(
            f"https://api.telegram.org/bot{token}/editMessageReplyMarkup",
            json={
                "chat_id": chat_id,
                "message_id": int(message_id),
                "reply_markup": {"inline_keyboard": [[{"text": label, "callback_data": "done"}]]},
            },
            timeout=10,
        )
    except Exception:
        pass


def get_telegram_updates(token: str, offset: int) -> List[Dict[str, Any]]:
    if not token:
        return []
    url = f"https://api.telegram.org/bot{token}/getUpdates"
    # timeout=0 ìœ¼ë¡œ ì¦‰ì‹œ ì‘ë‹µ (Streamlit Cloud long-polling ë¬¸ì œ ë°©ì§€)
    # allowed_updates ì— callback_query í¬í•¨í•´ì„œ ë²„íŠ¼ í´ë¦­ í™•ì‹¤íˆ ìˆ˜ì‹ 
    params = {
        "offset": offset,
        "timeout": 0,
        "allowed_updates": ["message", "callback_query"],
    }
    try:
        response = requests.get(url, params=params, timeout=15)
        response.raise_for_status()
        return response.json().get("result", [])
    except Exception as e:
        print(f"[getUpdates ì˜¤ë¥˜] {e}")
        return []


def wait_for_approval(
    config: AppConfig,
    progress,
    status_box,
    approval_message_id: Optional[str] = None,
) -> str:
    """
    í…”ë ˆê·¸ë¨ì—ì„œ ìŠ¹ì¸/êµí™˜ ì‘ë‹µ ëŒ€ê¸°.
    - callback_query (ë²„íŠ¼ í´ë¦­) ìš°ì„  ì²˜ë¦¬
    - í…ìŠ¤íŠ¸ ë©”ì‹œì§€ fallback ì§€ì› (ì´ì „ ë°©ì‹ í˜¸í™˜)
    """
    start_time = time.time()
    offset = _load_offset(config.telegram_offset_path)
    approve_set = {kw.lower() for kw in config.approve_keywords}
    swap_set = {kw.lower() for kw in config.swap_keywords}

    while time.time() - start_time < config.telegram_timeout_sec:
        _status_update(progress, status_box, 0.25, "í…”ë ˆê·¸ë¨ ë²„íŠ¼ ì‘ë‹µ ëŒ€ê¸° ì¤‘...")
        try:
            updates = get_telegram_updates(config.telegram_bot_token, offset)
        except Exception:
            updates = []

        for update in updates:
            update_id = update.get("update_id", 0)
            offset = max(offset, update_id + 1)

            # â”€â”€ ë²„íŠ¼ í´ë¦­ (callback_query) ì²˜ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            callback = update.get("callback_query")
            if callback:
                cb_data = (callback.get("data") or "").strip().lower()
                cb_id = callback.get("id", "")
                # chat_id: message > chat > id (ê°œì¸/ê·¸ë£¹ ëª¨ë‘ ì»¤ë²„)
                cb_msg = callback.get("message", {})
                cb_chat_id = str(cb_msg.get("chat", {}).get("id", ""))
                # from.id: ë²„íŠ¼ì„ ëˆ„ë¥¸ ì‚¬ëŒì˜ ê°œì¸ ID
                cb_from_id = str(callback.get("from", {}).get("id", ""))
                # fallback: from.id (ê°œì¸ ì±„íŒ…ì¼ ê²½ìš°)
                if not cb_chat_id:
                    cb_chat_id = cb_from_id

                print(f"[callback] data={cb_data} chat_id={cb_chat_id} from_id={cb_from_id} admin={config.telegram_admin_chat_id}")

                # ê´€ë¦¬ì ì²´í¬: ê·¸ë£¹ ID ë˜ëŠ” ê°œì¸ ID ì¤‘ í•˜ë‚˜ë¼ë„ ì¼ì¹˜í•˜ë©´ í†µê³¼
                if config.telegram_admin_chat_id:
                    admin_id = str(config.telegram_admin_chat_id)
                    if cb_chat_id != admin_id and cb_from_id != admin_id:
                        print(f"[callback] ê´€ë¦¬ì ì•„ë‹˜ - ë¬´ì‹œ (chat={cb_chat_id}, from={cb_from_id})")
                        continue

                if cb_data in ("approve", "approved"):
                    _answer_callback_query(config.telegram_bot_token, cb_id, "âœ… ìŠ¹ì¸ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    if approval_message_id:
                        _disable_approval_buttons(
                            config.telegram_bot_token,
                            config.telegram_admin_chat_id,
                            approval_message_id,
                            "approve",
                        )
                    _save_offset(config.telegram_offset_path, offset)
                    return "approve"

                if cb_data in ("swap", "exchange"):
                    _answer_callback_query(config.telegram_bot_token, cb_id, "ğŸ”„ êµí™˜ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
                    if approval_message_id:
                        _disable_approval_buttons(
                            config.telegram_bot_token,
                            config.telegram_admin_chat_id,
                            approval_message_id,
                            "swap",
                        )
                    _save_offset(config.telegram_offset_path, offset)
                    return "swap"

            # â”€â”€ í…ìŠ¤íŠ¸ ë©”ì‹œì§€ fallback â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            message = update.get("message", {})
            if not message:
                continue
            chat = message.get("chat", {})
            chat_id = str(chat.get("id", ""))
            if config.telegram_admin_chat_id and chat_id != str(config.telegram_admin_chat_id):
                continue
            text = (message.get("text") or "").strip().lower()
            if any(word in text for word in approve_set):
                _save_offset(config.telegram_offset_path, offset)
                return "approve"
            if any(word in text for word in swap_set):
                _save_offset(config.telegram_offset_path, offset)
                return "swap"

        _save_offset(config.telegram_offset_path, offset)
        time.sleep(3)  # 5ì´ˆâ†’3ì´ˆë¡œ ë‹¨ì¶•í•´ ì‘ë‹µì„± í–¥ìƒ

    return "approve"


def _write_local_log(path: str, record: dict) -> None:
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "a", encoding="utf-8") as file:
        file.write(json.dumps(record, ensure_ascii=False) + "\n")


def _format_hashtags(tags: List[str]) -> str:
    return " ".join(tags)


def _read_json_file(path: str, default: Any) -> Any:
    if not path:
        return default
    if not os.path.exists(path):
        return default
    try:
        with open(path, "r", encoding="utf-8") as file:
            return json.load(file)
    except Exception:
        return default


def _write_json_file(path: str, data: Any) -> None:
    if not path:
        return
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", encoding="utf-8") as file:
        json.dump(data, file, ensure_ascii=False, indent=2)


def _load_used_links(path: str) -> Dict[str, Any]:
    return _read_json_file(path, {"used": []})


def _is_used_link(used_data: Dict[str, Any], url: str) -> bool:
    used_list = used_data.get("used", [])
    return any(item.get("url") == url for item in used_list)


def _mark_used_link(path: str, url: str, status: str, title: str = "") -> None:
    used_data = _load_used_links(path)
    used_list = used_data.get("used", [])
    used_list.append(
        {
            "url": url,
            "status": status,
            "title": title,
            "ts": datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S"),
        }
    )
    used_data["used"] = used_list
    _write_json_file(path, used_data)


def _load_offset(path: str) -> int:
    data = _read_json_file(path, {"offset": 0})
    return int(data.get("offset", 0))


def _save_offset(path: str, offset: int) -> None:
    _write_json_file(path, {"offset": offset})


def _clear_inbox_unsaved(config: AppConfig, manifest_items: List[AssetItem]) -> int:
    """
    ì¸ë°•ìŠ¤ í´ë”ì—ì„œ ë¼ì´ë¸ŒëŸ¬ë¦¬(manifest)ì— ì €ì¥ë˜ì§€ ì•Šì€ íŒŒì¼ì„ ì‚­ì œ.
    session_stateì˜ inbox_current_files ê¸°ì¤€ìœ¼ë¡œ ì²˜ë¦¬.
    ë°˜í™˜ê°’: ì‚­ì œëœ íŒŒì¼ ìˆ˜
    """
    saved_paths = {item.path for item in manifest_items}
    prev_files: List[str] = st.session_state.get("inbox_current_files", [])
    deleted = 0
    for file_path in prev_files:
        if file_path not in saved_paths and os.path.exists(file_path):
            try:
                os.remove(file_path)
                deleted += 1
            except Exception:
                pass
    st.session_state["inbox_current_files"] = []
    return deleted


def _missing_required(config: AppConfig) -> List[str]:
    missing = []
    if not config.openai_api_key:
        missing.append("OPENAI_API_KEY")
    if not config.openai_tts_voices:
        missing.append("OPENAI_TTS_VOICE ë˜ëŠ” OPENAI_TTS_VOICES")
    if not config.sheet_id:
        missing.append("SHEET_ID")
    if not config.google_service_account_json:
        missing.append("GOOGLE_SERVICE_ACCOUNT_JSON")
    if not config.font_path:
        missing.append("FONT_PATH")
    if config.enable_youtube_upload:
        if not config.youtube_client_id:
            missing.append("YOUTUBE_CLIENT_ID")
        if not config.youtube_client_secret:
            missing.append("YOUTUBE_CLIENT_SECRET")
        if not config.youtube_refresh_token:
            missing.append("YOUTUBE_REFRESH_TOKEN")
    return missing


def _status_update(progress, status_box, pct: float, message: str) -> None:
    if progress:
        progress.progress(min(max(pct, 0.0), 1.0))
    if status_box:
        status_box.info(f"ì§„í–‰ ìƒíƒœ: {message}")


def _script_plan_text(script: Dict[str, Any]) -> str:
    body = script.get("body_script", [])
    middle = body[0] if body else ""
    return (
        f"ì£¼ì œ: {script.get('topic_theme','')}\n"
        f"ì œëª©: {script.get('video_title','')}\n"
        f"ë¬´ë“œ: {script.get('mood','')}\n"
        f"í›…: {script.get('hook_3_sec','')}\n"
        f"ì „ê°œ: {middle}\n"
        f"êµ¬ë…ìœ ë„: {script.get('cta_outro','')}\n"
        f"í•´ì‹œíƒœê·¸: {' '.join(script.get('hashtags', []))}"
    )


def _auto_jp_flow(config: AppConfig, progress, status_box, extra_hint: str = "") -> None:
    """
    í¬ë¡¤ë§ ì—†ì´ LLMì´ ì£¼ì œë¥¼ ìë™ ì„ ì •í•´ ì¼ë³¸ì¸ íƒ€ê²Ÿ ìˆì¸ ë¥¼ ìƒì„±í•˜ëŠ” ë©”ì¸ í”Œë¡œìš°.
    í…”ë ˆê·¸ë¨ ìŠ¹ì¸ â†’ TTS â†’ ì˜ìƒ ë Œë”ë§ â†’ ìœ íŠœë¸Œ ì—…ë¡œë“œ.
    """
    if not config.telegram_bot_token or not config.telegram_admin_chat_id:
        st.error("í…”ë ˆê·¸ë¨ ë´‡ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤. TELEGRAM_BOT_TOKEN, TELEGRAM_ADMIN_CHAT_IDë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return
    manifest_items = load_manifest(config.manifest_path)
    if not manifest_items:
        st.error("ì—ì…‹ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì´ë¯¸ì§€ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
        return

    # â”€â”€ ëŒ€ë³¸ ìƒì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    _status_update(progress, status_box, 0.10, "AI ëŒ€ë³¸ ìƒì„± ì¤‘ (ì£¼ì œ ìë™ ì„ ì •)...")
    try:
        script = generate_script_jp(config, extra_hint=extra_hint)
    except Exception as exc:
        st.error(f"ëŒ€ë³¸ ìƒì„± ì‹¤íŒ¨: {exc}")
        return

    topic_theme = script.get("topic_theme", "")
    video_title = script.get("video_title", "")
    hashtags = script.get("hashtags", [])
    hook_ja = script.get("hook_3_sec", "")
    hook_ko = script.get("hook_3_sec_ko", hook_ja)
    body_ja = script.get("body_script", [])
    body_ko = script.get("body_script_ko", body_ja)
    cta_ja = script.get("cta_outro", "")
    cta_ko = script.get("cta_outro_ko", cta_ja)
    pinned = script.get("pinned_comment", "")
    mood = script.get("mood", "exciting")
    bg_query = script.get("bg_search_query", "korea city street")
    top5_info = script.get("top5_info", [])

    st.info(f"ì£¼ì œ: **{topic_theme}** | ë¬´ë“œ: **{mood}**")

    # â”€â”€ BGM ë§¤ì¹­ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    _status_update(progress, status_box, 0.18, f"BGM ë§¤ì¹­ ì¤‘ (ë¬´ë“œ: {mood})")
    bgm_path = match_bgm_by_mood(config, mood)
    bgm_display = os.path.basename(bgm_path) if bgm_path else "ìë™ìƒì„±(ambient)"

    # â”€â”€ Pexels ë°°ê²½ ì˜ìƒ ë‹¤ìš´ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    bg_video_path: Optional[str] = None
    if config.pexels_api_key:
        _status_update(progress, status_box, 0.22, f"ë°°ê²½ ì˜ìƒ ë‹¤ìš´ë¡œë“œ ì¤‘ ({bg_query})")
        vid_dir = os.path.join(config.assets_dir, "bg_videos")
        bg_video_path = fetch_pexels_video(bg_query, config.pexels_api_key, vid_dir, config.width, config.height)
        if bg_video_path:
            st.info(f"ë°°ê²½ ì˜ìƒ: {os.path.basename(bg_video_path)}")
        else:
            st.warning("ë°°ê²½ ì˜ìƒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ â€” ì •ì  ì´ë¯¸ì§€ ë°°ê²½ìœ¼ë¡œ ëŒ€ì²´")

    # â”€â”€ TTSìš© í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    texts = _script_to_beats(script)

    # â”€â”€ ì—ì…‹ ì„ íƒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    mood_to_cat = {"mystery": "shocking", "exciting": "exciting", "informative": "humor"}
    content_category = mood_to_cat.get(mood, "exciting")
    assets: List[str] = []
    for _ in texts:
        asset = pick_asset_by_category(manifest_items, content_category)
        if not asset:
            asset = random.choice(manifest_items)
        assets.append(asset.path)

    # â”€â”€ Top5 ì„¤ëª… ì¡°ë¦½ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    top5_desc = ""
    if top5_info:
        lines = []
        for item in top5_info:
            rank = item.get("rank", "")
            name = item.get("name_ko", "")
            area = item.get("area", "")
            hint = item.get("address_hint", "")
            desc = item.get("desc_ko", "")
            desc_ja = item.get("desc_ja", "")
            lines.append(f"#{rank} {name} ({area}) â€” {hint}\n  KO: {desc}\n  JA: {desc_ja}")
        top5_desc = "\n".join(lines)

    # â”€â”€ YouTube ì„¤ëª… í…ìŠ¤íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    description_lines = [pinned, ""]
    if top5_info:
        description_lines += ["ğŸ“ Top5 ì •ë³´", top5_desc, ""]
    description_lines += [" ".join(hashtags)]
    description = "\n".join(description_lines)

    # â”€â”€ í…”ë ˆê·¸ë¨ ë¯¸ë¦¬ë³´ê¸° (í•œê¸€+ì¼ë³¸ì–´ ëŒ€ë³¸) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    body_preview = ""
    max_lines = max(len(body_ja), len(body_ko))
    for i in range(max_lines):
        ja_line = body_ja[i] if i < len(body_ja) else ""
        ko_line = body_ko[i] if i < len(body_ko) else ""
        body_preview += f"  {i+1}. JA: {ja_line}\n      KO: {ko_line}\n"

    top5_preview = ""
    if top5_desc:
        top5_preview = f"\nâ”â” Top5 ì •ë³´ â”â”\n{top5_desc}\n"

    request_text = (
        f"[ ìŠ¹ì¸ ìš”ì²­ ] ì¼ë³¸ì¸ íƒ€ê²Ÿ ìˆì¸ \n"
        f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
        f"ì£¼ì œ: {topic_theme}\n"
        f"ë¬´ë“œ: {mood}  |  BGM: {bgm_display}\n"
        f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
        f"[ì œëª© JA] {video_title}\n"
        f"[í•´ì‹œíƒœê·¸] {' '.join(hashtags)}\n\n"
        f"[í›… 3ì´ˆ]\nJA: {hook_ja}\nKO: {hook_ko}\n\n"
        f"[ë³¸ë¬¸]\n{body_preview}"
        f"[êµ¬ë…ìœ ë„]\nJA: {cta_ja}\nKO: {cta_ko}\n\n"
        f"[ê³ ì •ëŒ“ê¸€] {pinned}\n"
        f"{top5_preview}"
        f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
        f"ì•„ë˜ ë²„íŠ¼ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”."
    )

    # ëŒ€í‘œ ì—ì…‹ ë¯¸ë¦¬ë³´ê¸° ì „ì†¡
    if assets and os.path.exists(assets[0]):
        try:
            photo_api = f"https://api.telegram.org/bot{config.telegram_bot_token}/sendPhoto"
            with open(assets[0], "rb") as photo_file:
                requests.post(
                    photo_api,
                    data={"chat_id": config.telegram_admin_chat_id, "caption": "ëŒ€í‘œ ì‚¬ì§„ ë¯¸ë¦¬ë³´ê¸°"},
                    files={"photo": photo_file},
                    timeout=30,
                )
        except Exception:
            pass

    _status_update(progress, status_box, 0.30, "í…”ë ˆê·¸ë¨ ìŠ¹ì¸ ìš”ì²­ ì „ì†¡")
    approval_msg_id = send_telegram_approval_request(
        config.telegram_bot_token, config.telegram_admin_chat_id, request_text
    )
    decision = wait_for_approval(config, progress, status_box, approval_message_id=approval_msg_id)
    if decision == "swap":
        send_telegram_message(config.telegram_bot_token, config.telegram_admin_chat_id, "ğŸ”„ êµí™˜ ì²˜ë¦¬ë¨. ìƒˆ ì£¼ì œë¡œ ë‹¤ì‹œ ìƒì„±í•©ë‹ˆë‹¤.")
        _auto_jp_flow(config, progress, status_box, extra_hint=extra_hint)
        return

    # â”€â”€ TTS ìƒì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    now = datetime.utcnow().strftime("%Y%m%d_%H%M%S")
    audio_path = os.path.join(config.output_dir, f"tts_{now}.mp3")
    voice_id = pick_voice_id(config.openai_tts_voices)
    _status_update(progress, status_box, 0.50, "TTS ìƒì„± ì¤‘")
    try:
        tts_openai(config, "ã€‚".join(texts), audio_path, voice=voice_id)
    except Exception as tts_err:
        err_msg = f"âŒ TTS ìƒì„± ì‹¤íŒ¨: {tts_err}"
        st.error(err_msg)
        send_telegram_message(config.telegram_bot_token, config.telegram_admin_chat_id, err_msg)
        return

    # â”€â”€ ì˜ìƒ ë Œë”ë§ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    _status_update(progress, status_box, 0.65, "ì˜ìƒ ë Œë”ë§ ì¤‘")
    output_path = os.path.join(config.output_dir, f"shorts_{now}.mp4")
    render_video(
        config=config,
        asset_paths=assets,
        texts=texts,
        tts_audio_path=audio_path,
        output_path=output_path,
        bgm_path=bgm_path,
        bgm_volume=config.bgm_volume,
        bg_video_path=bg_video_path,
    )

    # â”€â”€ ìœ íŠœë¸Œ ì—…ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    video_id = ""
    video_url = ""
    if config.enable_youtube_upload:
        _status_update(progress, status_box, 0.85, "ìœ íŠœë¸Œ ì—…ë¡œë“œ")
        result = upload_video(
            config=config,
            file_path=output_path,
            title=video_title,
            description=description,
            tags=hashtags,
        )
        video_id = result.get("video_id", "")
        video_url = result.get("video_url", "")
    else:
        _status_update(progress, status_box, 0.85, "ìœ íŠœë¸Œ ì—…ë¡œë“œ(ìŠ¤í‚µ)")

    # â”€â”€ ë¡œê·¸ ê¸°ë¡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    log_row = {
        "date_jst": datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S"),
        "title_ja": video_title,
        "topic_theme": topic_theme,
        "hashtags_ja": " ".join(hashtags),
        "mood": mood,
        "pinned_comment": pinned,
        "voice_id": voice_id,
        "video_path": output_path,
        "youtube_video_id": video_id,
        "youtube_url": video_url,
        "status": "ok",
        "error": "",
    }
    try:
        append_publish_log(config, log_row)
    except Exception:
        pass
    _write_local_log(os.path.join(config.output_dir, "runs.jsonl"), log_row)

    _status_update(progress, status_box, 1.0, "ì™„ë£Œ")
    st.video(output_path)

    summary_text = (
        f"[ì™„ë£Œ] ì¼ë³¸ì¸ íƒ€ê²Ÿ ìˆì¸ \n"
        f"ì£¼ì œ: {topic_theme}\n"
        f"ì œëª©: {video_title}\n"
        f"ë¬´ë“œ: {mood}\n"
        f"ê³ ì •ëŒ“ê¸€: {pinned}\n"
    )
    if video_url:
        summary_text += f"ìœ íŠœë¸Œ: {video_url}"
    else:
        summary_text += f"ë¡œì»¬: {output_path}"
    send_telegram_message(config.telegram_bot_token, config.telegram_admin_chat_id, summary_text)


def run_streamlit_app() -> None:
    st.set_page_config(page_title="ìˆì¸  ìë™í™” ìŠ¤íŠœë””ì˜¤", layout="wide")
    config = load_config()
    ensure_dirs(
        [
            config.assets_dir,
            os.path.join(config.assets_dir, "images"),
            os.path.join(config.assets_dir, "inbox"),
            os.path.join(config.assets_dir, "bgm"),
            os.path.join(config.assets_dir, "bgm", "trending"),
            # ë¬´ë“œë³„ BGM ë””ë ‰í† ë¦¬ (mystery / exciting / informative)
            *[os.path.join(config.assets_dir, "bgm", mood) for mood in BGM_MOOD_CATEGORIES],
            os.path.join(config.assets_dir, "sfx"),
            os.path.join(config.assets_dir, "bg_videos"),
            os.path.dirname(config.manifest_path),
            config.output_dir,
        ]
    )

    st.sidebar.title("ìˆì¸  ìë™í™” ìŠ¤íŠœë””ì˜¤")
    st.sidebar.subheader("ìƒíƒœ")
    st.sidebar.write(f"ìë™ ì—…ë¡œë“œ: {'ì¼œì§' if config.enable_youtube_upload else 'êº¼ì§'}")
    st.sidebar.write(f"MoviePy ì‚¬ìš© ê°€ëŠ¥: {'ì˜ˆ' if MOVIEPY_AVAILABLE else 'ì•„ë‹ˆì˜¤'}")
    st.sidebar.write(f"BGM ëª¨ë“œ: {config.bgm_mode or 'off'}")
    st.sidebar.write(f"Pixabay BGM: {'ì—°ê²°ë¨' if config.pixabay_api_key else 'ë¯¸ì„¤ì •'}")
    if not MOVIEPY_AVAILABLE:
        st.sidebar.error(f"MoviePy ì˜¤ë¥˜: {MOVIEPY_ERROR}")

    st.sidebar.subheader("í•„ìˆ˜ API/ì„¤ì •")
    st.sidebar.markdown(
        "- `OPENAI_API_KEY`\n"
        "- `OPENAI_TTS_VOICE` ë˜ëŠ” `OPENAI_TTS_VOICES`\n"
        "- `SHEET_ID`\n"
        "- `GOOGLE_SERVICE_ACCOUNT_JSON`\n"
        "- `FONT_PATH`"
    )
    st.sidebar.subheader("ìë™ ìŠ¹ì¸(í…”ë ˆê·¸ë¨)")
    st.sidebar.markdown(
        "- `TELEGRAM_BOT_TOKEN`\n"
        "- `TELEGRAM_ADMIN_CHAT_ID`\n"
        "- `TELEGRAM_TIMEOUT_SEC`"
    )
    st.sidebar.subheader("ì„ íƒ")
    st.sidebar.markdown(
        "- `YOUTUBE_*` (ìë™ ì—…ë¡œë“œ)\n"
        "- `PIXABAY_API_KEY` (BGM ìë™ ë‹¤ìš´ë¡œë“œ)\n"
        "- `PEXELS_API_KEY` (ì´ë¯¸ì§€ ìë™ ìˆ˜ì§‘)\n"
        "- `SERPAPI_API_KEY` (íŠ¸ë Œë“œ ìˆ˜ì§‘)\n"
        "- `OPENAI_VISION_MODEL` (ì´ë¯¸ì§€ íƒœê·¸ ë¶„ì„)\n"
        "- `BGM_MODE`, `BGM_VOLUME` (ë°°ê²½ìŒì•…)\n\n"
        "**BGM ë¬´ë“œ í´ë”:** `assets/bgm/mystery/`, `assets/bgm/exciting/`, `assets/bgm/informative/`"
    )
    missing = _missing_required(config)
    if missing:
        st.sidebar.warning("ëˆ„ë½ëœ ì„¤ì •: " + ", ".join(missing))

    page = st.sidebar.radio("ë©”ë‰´", ["ìƒì„±", "í† í°", "ì—ì…‹", "ë¡œê·¸"])

    manifest_items = load_manifest(config.manifest_path)
    all_tags = list_tags(manifest_items)

    if page == "ìƒì„±":
        st.header("ìƒì„±")
        if missing:
            st.error("í•„ìˆ˜ API/ì„¤ì •ì´ ëˆ„ë½ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì¢Œì¸¡ ì‚¬ì´ë“œë°”ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        progress = st.progress(0.0)
        status_box = st.empty()

        st.subheader("ì¼ë³¸ì¸ íƒ€ê²Ÿ ìˆì¸  ìë™ ìƒì„± (AI ì£¼ì œ ìë™ ì„ ì •)")
        st.caption("í¬ë¡¤ë§ ì—†ì´ LLMì´ ë§¤ë²ˆ ìƒˆë¡œìš´ ì£¼ì œë¥¼ ì„ ì •í•©ë‹ˆë‹¤. ë¬´ë“œ(mystery/exciting/informative)ì— ë§ê²Œ BGMë„ ìë™ ë§¤ì¹­ë©ë‹ˆë‹¤.")

        extra_hint = st.text_input(
            "ì£¼ì œ íŒíŠ¸ (ì„ íƒ)",
            placeholder="ì˜ˆ: ë¶€ì‚° ë§›ì§‘, ì„œìš¸ ëª…ì†Œ, K-ë·°í‹° íŒ â€” ë¹„ì›Œë‘ë©´ AIê°€ ì•Œì•„ì„œ ì„ ì •",
            help="íŒíŠ¸ë¥¼ ì…ë ¥í•˜ë©´ LLMì´ í•´ë‹¹ ë°©í–¥ìœ¼ë¡œ ì£¼ì œë¥¼ ì¡ìŠµë‹ˆë‹¤. ë¹„ì›Œë‘ë©´ ì™„ì „ ëœë¤.",
        )
        auto_button = st.button("ìë™ ìƒì„± ì‹œì‘", type="primary")
        if auto_button:
            _auto_jp_flow(config, progress, status_box, extra_hint=extra_hint)

        st.divider()
        st.subheader("ìˆ˜ë™ ëŒ€ë³¸ ìƒì„± (íŒíŠ¸ ì…ë ¥ â†’ AI ìƒì„±)")
        manual_hint = st.text_area("ëŒ€ë³¸ íŒíŠ¸/ì•„ì´ë””ì–´ ì…ë ¥", height=100, placeholder="ì˜ˆ: í•œêµ­ í¸ì˜ì  ì‹ ìƒ ìŒë£Œ Top 5")
        generate_button = st.button("ëŒ€ë³¸ ìƒì„±")

        if generate_button and manual_hint:
            _status_update(progress, status_box, 0.05, "ëŒ€ë³¸ ìƒì„± ì¤‘")
            try:
                script = generate_script_jp(config, extra_hint=manual_hint)
                st.session_state["script_jp"] = script
                _status_update(progress, status_box, 0.2, "ëŒ€ë³¸ ìƒì„± ì™„ë£Œ")
            except Exception as exc:
                st.error(f"ëŒ€ë³¸ ìƒì„± ì‹¤íŒ¨: {exc}")

        script = st.session_state.get("script_jp")
        if script:
            st.subheader("ìƒì„±ëœ ëŒ€ë³¸")
            st.caption(f"ì£¼ì œ: **{script.get('topic_theme', '-')}** | ë¬´ë“œ: **{script.get('mood', '-')}**")
            video_title_val = st.text_input("ìœ íŠœë¸Œ ì œëª©", value=script.get("video_title", ""))
            hashtags_val = st.text_input(
                "í•´ì‹œíƒœê·¸(ê³µë°± êµ¬ë¶„)",
                value=" ".join(script.get("hashtags", [])),
            )

            # í•œê¸€/ì¼ë³¸ì–´ ëŒ€ë³¸ ë‚˜ë€íˆ í‘œì‹œ
            col_ja, col_ko = st.columns(2)
            with col_ja:
                st.markdown("**ğŸ‡¯ğŸ‡µ ì¼ë³¸ì–´ ëŒ€ë³¸**")
                hook_val = st.text_input("3ì´ˆ í›… (JA)", value=script.get("hook_3_sec", ""), key="hook_ja")
                body_val = st.text_area(
                    "ë³¸ë¬¸ (JA, ì¤„ êµ¬ë¶„)",
                    value="\n".join(script.get("body_script", [])),
                    height=200,
                    key="body_ja",
                )
                cta_val = st.text_input("êµ¬ë… ìœ ë„ (JA)", value=script.get("cta_outro", ""), key="cta_ja")
            with col_ko:
                st.markdown("**ğŸ‡°ğŸ‡· í•œêµ­ì–´ ëŒ€ë³¸ (ì°¸ê³ ìš©)**")
                st.text_input("3ì´ˆ í›… (KO)", value=script.get("hook_3_sec_ko", ""), key="hook_ko", disabled=True)
                st.text_area(
                    "ë³¸ë¬¸ (KO)",
                    value="\n".join(script.get("body_script_ko", [])),
                    height=200,
                    key="body_ko",
                    disabled=True,
                )
                st.text_input("êµ¬ë… ìœ ë„ (KO)", value=script.get("cta_outro_ko", ""), key="cta_ko", disabled=True)

            pinned_val = st.text_input("ê³ ì • ëŒ“ê¸€", value=script.get("pinned_comment", ""))

            # Top5 ì •ë³´ í‘œì‹œ
            top5_info = script.get("top5_info", [])
            if top5_info:
                st.markdown("**ğŸ“ Top5 ì •ë³´ (ì„¤ëª…ë€ ìë™ í¬í•¨)**")
                for item in top5_info:
                    st.markdown(
                        f"**#{item.get('rank')} {item.get('name_ko','')}** "
                        f"({item.get('area','')}) â€” {item.get('address_hint','')}\n\n"
                        f">{item.get('desc_ko','')} / {item.get('desc_ja','')}"
                    )

            render_button = st.button("ì˜ìƒ ë§Œë“¤ê¸°")
            if render_button:
                if missing:
                    st.error("í•„ìˆ˜ API/ì„¤ì •ì´ ëˆ„ë½ë˜ì–´ ìˆì–´ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    return
                if not MOVIEPY_AVAILABLE:
                    st.error(f"MoviePyê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {MOVIEPY_ERROR}")
                    return
                if not manifest_items:
                    st.error("ì—ì…‹ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì´ë¯¸ì§€ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
                else:
                    body_lines = [l.strip() for l in body_val.split("\n") if l.strip()]
                    texts = [hook_val] + body_lines + ([cta_val] if cta_val else [])
                    if not texts:
                        st.error("ë Œë”ë§í•  ë¬¸ì¥ì´ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        mood = script.get("mood", "exciting")
                        _status_update(progress, status_box, 0.15, f"BGM ë§¤ì¹­ ì¤‘ ({mood})")
                        bgm_path = match_bgm_by_mood(config, mood)

                        mood_to_cat = {"mystery": "shocking", "exciting": "exciting", "informative": "humor"}
                        cat = mood_to_cat.get(mood, "exciting")
                        assets = []
                        for _ in texts:
                            asset = pick_asset_by_category(manifest_items, cat)
                            if not asset:
                                asset = random.choice(manifest_items)
                            assets.append(asset.path)

                        # Pexels ë°°ê²½ ì˜ìƒ ë‹¤ìš´ë¡œë“œ ì‹œë„
                        bg_vid_manual: Optional[str] = None
                        if config.pexels_api_key:
                            _status_update(progress, status_box, 0.25, "ë°°ê²½ ì˜ìƒ ë‹¤ìš´ë¡œë“œ ì¤‘")
                            bg_query_m = script.get("bg_search_query", "korea city")
                            vid_dir_m = os.path.join(config.assets_dir, "bg_videos")
                            bg_vid_manual = fetch_pexels_video(bg_query_m, config.pexels_api_key, vid_dir_m, config.width, config.height)

                        _status_update(progress, status_box, 0.3, "TTS ìƒì„±")
                        now = datetime.utcnow().strftime("%Y%m%d_%H%M%S")
                        audio_path = os.path.join(config.output_dir, f"tts_{now}.mp3")
                        voice_id = pick_voice_id(config.openai_tts_voices)
                        tts_openai(config, "ã€‚".join(texts), audio_path, voice=voice_id)
                        _status_update(progress, status_box, 0.6, "ì˜ìƒ ë Œë”ë§")
                        output_path = os.path.join(config.output_dir, f"shorts_{now}.mp4")
                        render_video(
                            config=config,
                            asset_paths=assets,
                            texts=texts,
                            tts_audio_path=audio_path,
                            output_path=output_path,
                            bgm_path=bgm_path,
                            bgm_volume=config.bgm_volume,
                            bg_video_path=bg_vid_manual,
                        )
                        video_id = ""
                        video_url = ""
                        if config.enable_youtube_upload:
                            _status_update(progress, status_box, 0.85, "ìœ íŠœë¸Œ ì—…ë¡œë“œ")
                            result = upload_video(
                                config=config,
                                file_path=output_path,
                                title=video_title_val,
                                description=pinned_val + "\n\n" + hashtags_val,
                                tags=hashtags_val.split(),
                            )
                            video_id = result.get("video_id", "")
                            video_url = result.get("video_url", "")
                        else:
                            _status_update(progress, status_box, 0.85, "ìœ íŠœë¸Œ ì—…ë¡œë“œ(ìŠ¤í‚µ)")
                        log_row = {
                            "date_jst": datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S"),
                            "title_ja": video_title_val,
                            "topic_theme": script.get("topic_theme", ""),
                            "hashtags_ja": hashtags_val,
                            "mood": mood,
                            "pinned_comment": pinned_val,
                            "voice_id": voice_id,
                            "video_path": output_path,
                            "youtube_video_id": video_id,
                            "youtube_url": video_url,
                            "status": "ok",
                            "error": "",
                        }
                        try:
                            append_publish_log(config, log_row)
                        except Exception:
                            pass
                        _write_local_log(os.path.join(config.output_dir, "runs.jsonl"), log_row)
                        _status_update(progress, status_box, 1.0, "ì™„ë£Œ")
                        st.video(output_path)
                        if video_url:
                            st.success(video_url)

    if page == "í† í°":
        st.header("ìœ íŠœë¸Œ ë¦¬í”„ë ˆì‹œ í† í° ë°œê¸‰")
        st.markdown(
            "1) OAuth í´ë¼ì´ì–¸íŠ¸ ID/Secret ì…ë ¥\n"
            "2) Redirect URI ì„¤ì •\n"
            "3) ìŠ¹ì¸ URL ì—´ê¸° â†’ ë¡œê·¸ì¸/ë™ì˜\n"
            "4) codeë¥¼ ë¶™ì—¬ë„£ê³  í† í° êµí™˜"
        )
        st.caption(
            "Redirect URIëŠ” Google Cloud Credentialsì— ë“±ë¡ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤. "
            "ë¡œì»¬ì´ë¼ë©´ ë³´í†µ http://localhost:8501 ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤."
        )

        client_id = st.text_input("OAuth í´ë¼ì´ì–¸íŠ¸ ID", value=config.youtube_client_id or "")
        client_secret = st.text_input(
            "OAuth í´ë¼ì´ì–¸íŠ¸ Secret", value=config.youtube_client_secret or "", type="password"
        )
        redirect_uri = st.text_input(
            "Redirect URI",
            value=_get_secret("OAUTH_REDIRECT_URI", "") or "",
            placeholder="http://localhost:8501",
        )
        scope = st.text_input(
            "Scope",
            value="https://www.googleapis.com/auth/youtube.upload",
        )
        prompt_consent = st.checkbox("ì¬ë™ì˜ ê°•ì œ(prompt=consent)", value=True)

        if st.button("ìŠ¹ì¸ URL ìƒì„±"):
            if not client_id or not redirect_uri:
                st.error("í´ë¼ì´ì–¸íŠ¸ IDì™€ Redirect URIë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
            else:
                st.session_state["auth_url"] = build_google_oauth_url(
                    client_id=client_id,
                    redirect_uri=redirect_uri,
                    scope=scope.strip(),
                    prompt_consent=prompt_consent,
                )

        auth_url = st.session_state.get("auth_url", "")
        if auth_url:
            st.markdown(f"[ìŠ¹ì¸ í˜ì´ì§€ ì—´ê¸°]({auth_url})")
            st.code(auth_url)

        default_code = _get_query_param("code")
        auth_code = st.text_input("ìŠ¹ì¸ ì½”ë“œ(code)", value=default_code or "")

        if st.button("í† í° êµí™˜"):
            if not client_id or not client_secret or not redirect_uri or not auth_code:
                st.error("ëª¨ë“  ê°’ì„ ì…ë ¥í•œ í›„ ì§„í–‰í•˜ì„¸ìš”.")
            else:
                try:
                    result = exchange_oauth_code_for_token(
                        client_id=client_id,
                        client_secret=client_secret,
                        code=auth_code.strip(),
                        redirect_uri=redirect_uri,
                    )
                    refresh_token = result.get("refresh_token", "")
                    if refresh_token:
                        st.success("ë¦¬í”„ë ˆì‹œ í† í° ë°œê¸‰ ì„±ê³µ")
                        st.code(refresh_token)
                        st.info("ì´ ê°’ì„ `.streamlit/secrets.toml`ì˜ `YOUTUBE_REFRESH_TOKEN`ì— ë„£ìœ¼ì„¸ìš”.")
                    else:
                        st.warning(
                            "refresh_tokenì´ ì‘ë‹µì— ì—†ìŠµë‹ˆë‹¤. "
                            "ì²˜ìŒ ìŠ¹ì¸ì¼ ë•Œë§Œ ë‚´ë ¤ì˜¤ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. "
                            "prompt=consentë¥¼ ì¼œê³  ë‹¤ì‹œ ìŠ¹ì¸í•˜ì„¸ìš”."
                        )
                        st.json(result)
                except Exception as exc:
                    st.error(f"í† í° êµí™˜ ì‹¤íŒ¨: {exc}")

    if page == "ì—ì…‹":
        st.header("ì—ì…‹")
        upload_files = st.file_uploader("ì´ë¯¸ì§€ ì—…ë¡œë“œ", type=["jpg", "jpeg", "png"], accept_multiple_files=True)
        tag_input = st.text_input("íƒœê·¸(ì‰¼í‘œ êµ¬ë¶„)")
        if st.button("ì—…ë¡œë“œ ì €ì¥") and upload_files:
            for file in upload_files:
                save_path = os.path.join(config.assets_dir, "images", file.name)
                with open(save_path, "wb") as out_file:
                    out_file.write(file.getbuffer())
                add_asset(config.manifest_path, save_path, tags_from_text(tag_input))
            st.success("ì—ì…‹ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

        st.subheader("BGM ì—…ë¡œë“œ")
        bgm_files = st.file_uploader(
            "ì˜¤ë””ì˜¤ ì—…ë¡œë“œ",
            type=["mp3", "wav", "m4a", "aac", "ogg"],
            accept_multiple_files=True,
            key="bgm_upload",
        )
        mood_labels = list(BGM_MOOD_CATEGORIES.keys())
        bgm_target = st.selectbox(
            "ì €ì¥ ìœ„ì¹˜",
            ["ì¼ë°˜ BGM"] + [f"ë¬´ë“œ: {m}" for m in mood_labels],
        )
        if st.button("BGM ì €ì¥") and bgm_files:
            if bgm_target.startswith("ë¬´ë“œ: "):
                mood_name = bgm_target.replace("ë¬´ë“œ: ", "")
                target_dir = os.path.join(config.assets_dir, "bgm", mood_name)
            else:
                target_dir = os.path.join(config.assets_dir, "bgm")
            os.makedirs(target_dir, exist_ok=True)
            for file in bgm_files:
                save_path = os.path.join(target_dir, file.name)
                with open(save_path, "wb") as out_file:
                    out_file.write(file.getbuffer())
            st.success("BGMì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

        st.subheader("Pixabay BGM ìˆ˜ë™ ë‹¤ìš´ë¡œë“œ")
        if not config.pixabay_api_key:
            st.warning("PIXABAY_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. `.streamlit/secrets.toml`ì— ì¶”ê°€í•˜ì„¸ìš”.")
        else:
            pixabay_mood = st.selectbox("BGM ë¬´ë“œ", mood_labels, key="pixabay_mood")
            pixabay_count = st.slider("ë‹¤ìš´ë¡œë“œ ê°œìˆ˜", 1, 5, 3, key="pixabay_count")
            if st.button("Pixabayì—ì„œ BGM ë‹¤ìš´ë¡œë“œ"):
                mood_info = BGM_MOOD_CATEGORIES[pixabay_mood]
                bgm_out_dir = os.path.join(config.assets_dir, "bgm", pixabay_mood)
                query = random.choice(mood_info["pixabay_queries"])
                downloaded_bgms = []
                for _ in range(pixabay_count):
                    path = fetch_bgm_from_pixabay(
                        api_key=config.pixabay_api_key,
                        category=pixabay_mood,
                        output_dir=bgm_out_dir,
                        custom_query=query,
                    )
                    if path:
                        downloaded_bgms.append(path)
                if downloaded_bgms:
                    st.success(f"{len(downloaded_bgms)}ê°œ BGMì„ `bgm/{pixabay_mood}/`ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
                    for p in downloaded_bgms:
                        st.audio(p)
                else:
                    st.error("BGM ë‹¤ìš´ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. API í‚¤ë‚˜ ë„¤íŠ¸ì›Œí¬ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

        st.subheader("AI ì´ë¯¸ì§€ ìˆ˜ì§‘(SerpAPI)")
        collect_query = st.text_input("ê²€ìƒ‰ì–´")
        collect_count = st.slider("ìˆ˜ì§‘ ê°œìˆ˜", 4, 20, 8)
        if st.button("ì¸ë°•ìŠ¤ë¡œ ìˆ˜ì§‘"):
            try:
                if not collect_query.strip():
                    st.error("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
                    return
                # ìƒˆ ê²€ìƒ‰ì–´ë¡œ ìˆ˜ì§‘ ì‹œ ì´ì „ ì¸ë°•ìŠ¤ ì´ˆê¸°í™”
                prev_query = st.session_state.get("inbox_source_key", "")
                if f"serpapi_{collect_query}" != prev_query:
                    _clear_inbox_unsaved(config, manifest_items)
                    st.session_state["inbox_source_key"] = f"serpapi_{collect_query}"
                    st.session_state["ai_tag_map"] = {}
                    st.session_state["ai_category_map"] = {}
                inbox_dir = os.path.join(config.assets_dir, "inbox")
                collected = collect_images_serpapi(
                    query=collect_query,
                    api_key=config.serpapi_api_key,
                    output_dir=inbox_dir,
                    limit=collect_count,
                )
                st.session_state["inbox_current_files"] = collected
                st.success(f"{len(collected)}ê°œ ì´ë¯¸ì§€ë¥¼ ì¸ë°•ìŠ¤ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
            except Exception as exc:
                st.error(f"ìˆ˜ì§‘ ì‹¤íŒ¨: {exc}")

        st.subheader("URL ëª©ë¡ìœ¼ë¡œ ì´ë¯¸ì§€ ìˆ˜ì§‘(ê¶Œí•œ ë³´ìœ  í•„ìˆ˜)")
        st.caption("ì €ì‘ê¶Œì´ ìˆëŠ” ì´ë¯¸ì§€/ë°ˆì€ ê¶Œí•œì´ ìˆì„ ë•Œë§Œ ì‚¬ìš©í•˜ì„¸ìš”.")
        url_text = st.text_area("ì´ë¯¸ì§€ URL ëª©ë¡ (ì¤„ë°”ê¿ˆ)", height=120, key="url_import")
        url_limit = st.slider("URL ìµœëŒ€ ìˆ˜ì§‘ ê°œìˆ˜", 1, 50, 20, key="url_import_limit")
        url_confirm = st.checkbox("ì´ URLì˜ ì´ë¯¸ì§€ ì‚¬ìš© ê¶Œí•œì„ ë³´ìœ í–ˆìŠµë‹ˆë‹¤.")
        if st.button("URLë¡œ ì¸ë°•ìŠ¤ ì €ì¥"):
            if not url_confirm:
                st.error("ê¶Œí•œ í™•ì¸ì— ë™ì˜í•´ì•¼ í•©ë‹ˆë‹¤.")
            else:
                urls = [line.strip() for line in url_text.splitlines() if line.strip()]
                if not urls:
                    st.error("URLì„ ì…ë ¥í•˜ì„¸ìš”.")
                else:
                    try:
                        new_url_key = f"url_{str(sorted(urls))}"
                        if new_url_key != st.session_state.get("inbox_source_key", ""):
                            _clear_inbox_unsaved(config, manifest_items)
                            st.session_state["inbox_source_key"] = new_url_key
                            st.session_state["ai_tag_map"] = {}
                            st.session_state["ai_category_map"] = {}
                        inbox_dir = os.path.join(config.assets_dir, "inbox")
                        collected = download_images_from_urls(urls, inbox_dir, limit=url_limit)
                        st.session_state["inbox_current_files"] = collected
                        st.success(f"{len(collected)}ê°œ ì´ë¯¸ì§€ë¥¼ ì¸ë°•ìŠ¤ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
                    except Exception as exc:
                        st.error(f"URL ìˆ˜ì§‘ ì‹¤íŒ¨: {exc}")

        st.subheader("ë„¤ì´ë²„ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ì´ë¯¸ì§€ ìˆ˜ì§‘(ê¶Œí•œ ë³´ìœ  í•„ìˆ˜)")
        st.caption("í¼ê°€ê¸°ê°€ í—ˆìš©ëœ í¬ìŠ¤íŠ¸ URLë§Œ ë„£ì–´ì£¼ì„¸ìš”.")
        post_text = st.text_area("í¬ìŠ¤íŠ¸ URL ëª©ë¡ (ì¤„ë°”ê¿ˆ)", height=120, key="naver_post_import")
        post_limit = st.slider("í¬ìŠ¤íŠ¸ ì´ë¯¸ì§€ ìµœëŒ€ ìˆ˜ì§‘ ê°œìˆ˜", 1, 100, 40, key="naver_post_limit")
        post_confirm = st.checkbox("í•´ë‹¹ í¬ìŠ¤íŠ¸ ì´ë¯¸ì§€ ì‚¬ìš© ê¶Œí•œì„ ë³´ìœ í–ˆìŠµë‹ˆë‹¤.")
        if st.button("í¬ìŠ¤íŠ¸ì—ì„œ ì¸ë°•ìŠ¤ ì €ì¥"):
            if not post_confirm:
                st.error("ê¶Œí•œ í™•ì¸ì— ë™ì˜í•´ì•¼ í•©ë‹ˆë‹¤.")
            else:
                post_urls = [line.strip() for line in post_text.splitlines() if line.strip()]
                if not post_urls:
                    st.error("í¬ìŠ¤íŠ¸ URLì„ ì…ë ¥í•˜ì„¸ìš”.")
                else:
                    # ìƒˆ URL ì…ë ¥ ì‹œ ì´ì „ ìˆ˜ì§‘ íŒŒì¼ ì´ˆê¸°í™” (ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ì €ì¥ëœ ê±´ ë³´í˜¸)
                    new_source_key = str(sorted(post_urls))
                    prev_source_key = st.session_state.get("inbox_source_key", "")
                    if new_source_key != prev_source_key:
                        prev_files = st.session_state.get("inbox_current_files", [])
                        saved_paths = {item.path for item in load_manifest(config.manifest_path)}
                        deleted_count = 0
                        for old_file in prev_files:
                            if old_file not in saved_paths and os.path.exists(old_file):
                                try:
                                    os.remove(old_file)
                                    deleted_count += 1
                                except Exception:
                                    pass
                        if deleted_count:
                            st.info(f"ì´ì „ ìˆ˜ì§‘ ì‚¬ì§„ {deleted_count}ê°œë¥¼ ì´ˆê¸°í™”í–ˆìŠµë‹ˆë‹¤.")
                        st.session_state["inbox_current_files"] = []
                        st.session_state["inbox_source_key"] = new_source_key
                        # AI íƒœê·¸/ì¹´í…Œê³ ë¦¬ ìºì‹œë„ ì´ˆê¸°í™”
                        st.session_state["ai_tag_map"] = {}
                        st.session_state["ai_category_map"] = {}
                    try:
                        inbox_dir = os.path.join(config.assets_dir, "inbox")
                        total_urls, downloaded_count = collect_images_from_post_urls(
                            post_urls=post_urls,
                            output_dir=inbox_dir,
                            limit=post_limit,
                        )
                        if total_urls == 0:
                            st.warning("ì´ë¯¸ì§€ URLì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                        else:
                            # ë°©ê¸ˆ ìˆ˜ì§‘ëœ íŒŒì¼ë§Œ session_stateì— ê¸°ë¡
                            inbox_dir_path = os.path.join(config.assets_dir, "inbox")
                            all_inbox = [
                                os.path.join(inbox_dir_path, f)
                                for f in os.listdir(inbox_dir_path)
                                if f.lower().endswith((".jpg", ".jpeg", ".png"))
                            ]
                            st.session_state["inbox_current_files"] = sorted(
                                all_inbox, key=os.path.getmtime, reverse=True
                            )[:downloaded_count]
                            st.success(f"ë°œê²¬ {total_urls}ê°œ / ì €ì¥ {downloaded_count}ê°œ")
                    except Exception as exc:
                        st.error(f"í¬ìŠ¤íŠ¸ ìˆ˜ì§‘ ì‹¤íŒ¨: {exc}")

        st.subheader("ì¼ë³¸ íŠ¸ë Œë“œ ìë™ ìˆ˜ì§‘(Pexels)")
        st.caption("SerpAPIë¡œ ì¼ë³¸ íŠ¸ë Œë“œ í‚¤ì›Œë“œë¥¼ ë§Œë“¤ê³ , Pexelsì—ì„œ ì´ë¯¸ì§€ë¥¼ ìë™ ìˆ˜ì§‘í•©ë‹ˆë‹¤.")
        auto_count = st.slider("ìë™ ìˆ˜ì§‘ ê°œìˆ˜", 4, 30, 12, key="auto_collect_count")
        auto_queries = st.slider("ê²€ìƒ‰ì–´ ê°œìˆ˜", 2, 6, 4, key="auto_collect_queries")
        if st.button("ì¼ë³¸ íŠ¸ë Œë“œ ìë™ ìˆ˜ì§‘"):
            # ìƒˆ ìˆ˜ì§‘ ì‹œ ì´ì „ ì¸ë°•ìŠ¤ ì´ˆê¸°í™”
            _clear_inbox_unsaved(config, manifest_items)
            try:
                inbox_dir = os.path.join(config.assets_dir, "inbox")
                collected, queries = collect_images_auto_trend(
                    config=config,
                    output_dir=inbox_dir,
                    total_count=auto_count,
                    max_queries=auto_queries,
                )
                st.session_state["inbox_current_files"] = collected
                st.session_state["inbox_source_key"] = f"trend_{datetime.utcnow().isoformat()}"
                st.session_state["ai_tag_map"] = {}
                st.session_state["ai_category_map"] = {}
                st.write("ì‚¬ìš© ê²€ìƒ‰ì–´:", ", ".join(queries))
                st.success(f"{len(collected)}ê°œ ì´ë¯¸ì§€ë¥¼ ì¸ë°•ìŠ¤ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
            except Exception as exc:
                st.error(f"ìë™ ìˆ˜ì§‘ ì‹¤íŒ¨: {exc}")

        # ì¸ë°•ìŠ¤ í‘œì‹œ: session_state ê¸°ë°˜ (í˜„ì¬ ìˆ˜ì§‘ë¶„ë§Œ)
        inbox_files = [
            f for f in st.session_state.get("inbox_current_files", [])
            if os.path.exists(f)
        ]
        # í•˜ìœ„ í˜¸í™˜: session_stateê°€ ë¹„ì–´ìˆìœ¼ë©´ í´ë” ì „ì²´ í‘œì‹œ
        if not inbox_files:
            inbox_dir = os.path.join(config.assets_dir, "inbox")
            if os.path.exists(inbox_dir):
                inbox_files = [
                    os.path.join(inbox_dir, f)
                    for f in os.listdir(inbox_dir)
                    if f.lower().endswith((".jpg", ".jpeg", ".png"))
                ]
        if inbox_files:
            st.subheader("ì¸ë°•ìŠ¤")
            inbox_tags = st.text_input("ì¸ë°•ìŠ¤ íƒœê·¸(ì‰¼í‘œ êµ¬ë¶„)")
            preset_map = {
                "ì¶©ê²©/ë°˜ì „": ["shock", "wow"],
                "ì›ƒê¹€/ë¹„ê¼¼": ["laugh"],
                "ì–´ì´ì—†ìŒ/ë‹¹í™©": ["awkward", "facepalm"],
                "ì§œì¦/ë¶„ë…¸": ["angry"],
                "ê·€ì—¬ì›€/íë§": ["cute"],
                "ì „ê°œ/ìŠ¤í† ë¦¬": ["plot"],
                "ì—”ë”©/ë§ˆë¬´ë¦¬": ["ending"],
            }
            preset_choices = list(preset_map.keys())
            selected_presets = st.multiselect("ìƒí™© í”„ë¦¬ì…‹", options=preset_choices)
            add_pepe_tag = st.checkbox("í˜í˜ ê¸°ë³¸ íƒœê·¸ ì¶”ê°€", value=False)
            select_all = st.checkbox("ì „ì²´ ì„ íƒ", value=False)
            ai_apply = st.checkbox("AI íƒœê·¸ ìë™ ì ìš©", value=False)

            # NEW: ì½˜í…ì¸  ì¹´í…Œê³ ë¦¬ AI ìë™ ì ìš© ì˜µì…˜
            ai_category_apply = st.checkbox("AI ì½˜í…ì¸  ì¹´í…Œê³ ë¦¬ ìë™ ì ìš© (íƒœê·¸ë¡œ ì €ì¥)", value=False)

            selected_files: List[str] = []
            for file_path in inbox_files:
                st.image(file_path, width=200)
                if select_all or st.checkbox(f"ì„ íƒ: {os.path.basename(file_path)}", key=f"select_{file_path}"):
                    selected_files.append(file_path)
                ai_tag_map = st.session_state.get("ai_tag_map", {})
                if file_path in ai_tag_map:
                    st.caption(f"AI íƒœê·¸: {', '.join(ai_tag_map[file_path])}")
                # NEW: ì¹´í…Œê³ ë¦¬ í‘œì‹œ
                ai_cat_map = st.session_state.get("ai_category_map", {})
                if file_path in ai_cat_map:
                    st.caption(f"AI ì¹´í…Œê³ ë¦¬: {ai_cat_map[file_path]}")

            if st.button("ì„ íƒí•œ ì§¤ AI íƒœê·¸ ë¶„ì„"):
                if not config.openai_api_key:
                    st.error("OPENAI_API_KEYê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                else:
                    targets = selected_files or inbox_files
                    tag_map = st.session_state.get("ai_tag_map", {})
                    cat_map = st.session_state.get("ai_category_map", {})
                    progress_bar = st.progress(0.0)
                    for index, path in enumerate(targets):
                        try:
                            tags = analyze_image_tags(config, path)
                            tag_map[path] = tags
                            # NEW: ì¹´í…Œê³ ë¦¬ë„ í•¨ê»˜ ë¶„ì„
                            cat = analyze_image_content_category(config, path)
                            cat_map[path] = cat
                        except Exception:
                            continue
                        progress_bar.progress((index + 1) / max(len(targets), 1))
                    st.session_state["ai_tag_map"] = tag_map
                    st.session_state["ai_category_map"] = cat_map
                    st.success("AI íƒœê·¸ + ì¹´í…Œê³ ë¦¬ ë¶„ì„ ì™„ë£Œ")

            if st.button("ì„ íƒí•œ ì§¤ ì €ì¥"):
                base_tags = tags_from_text(inbox_tags)
                for preset in selected_presets:
                    base_tags.extend(preset_map.get(preset, []))
                base_tags = list(set(base_tags))
                ai_cat_map = st.session_state.get("ai_category_map", {})
                for file_path in selected_files:
                    tags = list(base_tags)
                    if add_pepe_tag:
                        tags.append("pepe")
                    if ai_apply:
                        ai_tag_map = st.session_state.get("ai_tag_map", {})
                        tags.extend(ai_tag_map.get(file_path, []))
                    # NEW: ì¹´í…Œê³ ë¦¬ë¥¼ íƒœê·¸ë¡œ ì €ì¥
                    if ai_category_apply and file_path in ai_cat_map:
                        tags.append(ai_cat_map[file_path])
                    tags = list(set(tags))
                    add_asset(config.manifest_path, file_path, tags)
                # ì €ì¥ëœ íŒŒì¼ì€ ì¸ë°•ìŠ¤ ëª©ë¡ì—ì„œ ì œê±° (ë‹¤ìŒ ì´ˆê¸°í™” ë•Œ ì‚­ì œ ëŒ€ìƒì—ì„œ ì œì™¸)
                saved_set = set(selected_files)
                current = st.session_state.get("inbox_current_files", [])
                st.session_state["inbox_current_files"] = [f for f in current if f not in saved_set]
                st.success(f"ì„ íƒí•œ ì§¤ {len(selected_files)}ê°œê°€ ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")
                st.rerun()

        st.subheader("ë¼ì´ë¸ŒëŸ¬ë¦¬")
        if manifest_items:
            selected_tag = st.selectbox("íƒœê·¸ í•„í„°", options=["(ì „ì²´)"] + all_tags)
            filtered = manifest_items if selected_tag == "(ì „ì²´)" else filter_assets_by_tags(manifest_items, [selected_tag])
            lib_select_all = st.checkbox("ë¼ì´ë¸ŒëŸ¬ë¦¬ ì „ì²´ ì„ íƒ", value=False, key="lib_select_all")
            delete_files = st.checkbox("ì„ íƒ í•­ëª© íŒŒì¼ë„ ì‚­ì œ", value=False, key="lib_delete_files")
            keep_tags = st.checkbox("AI íƒœê·¸ ì ìš© ì‹œ ê¸°ì¡´ íƒœê·¸ ìœ ì§€", value=True, key="lib_ai_keep")
            selected_assets: List[AssetItem] = []
            for item in filtered:
                st.image(item.path, width=200, caption=",".join(item.tags))
                if lib_select_all or st.checkbox(f"ì„ íƒ: {item.asset_id}", key=f"lib_select_{item.asset_id}"):
                    selected_assets.append(item)
                lib_ai_map = st.session_state.get("library_ai_tag_map", {})
                if item.asset_id in lib_ai_map:
                    st.caption(f"AI íƒœê·¸: {', '.join(lib_ai_map[item.asset_id])}")
                # NEW: ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¹´í…Œê³ ë¦¬ í‘œì‹œ
                lib_cat_map = st.session_state.get("library_ai_cat_map", {})
                if item.asset_id in lib_cat_map:
                    st.caption(f"AI ì¹´í…Œê³ ë¦¬: {lib_cat_map[item.asset_id]}")

            if st.button("ì„ íƒí•œ ì—ì…‹ AI íƒœê·¸ ë¶„ì„"):
                if not config.openai_api_key:
                    st.error("OPENAI_API_KEYê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                else:
                    targets = selected_assets or filtered
                    tag_map = st.session_state.get("library_ai_tag_map", {})
                    cat_map = st.session_state.get("library_ai_cat_map", {})
                    progress_bar = st.progress(0.0)
                    for index, item in enumerate(targets):
                        try:
                            tags = analyze_image_tags(config, item.path)
                            tag_map[item.asset_id] = tags
                            # NEW: ì¹´í…Œê³ ë¦¬ë„ í•¨ê»˜ ë¶„ì„
                            cat = analyze_image_content_category(config, item.path)
                            cat_map[item.asset_id] = cat
                        except Exception:
                            continue
                        progress_bar.progress((index + 1) / max(len(targets), 1))
                    st.session_state["library_ai_tag_map"] = tag_map
                    st.session_state["library_ai_cat_map"] = cat_map
                    st.success("AI íƒœê·¸ + ì¹´í…Œê³ ë¦¬ ë¶„ì„ ì™„ë£Œ")

            if st.button("AI íƒœê·¸ë¡œ ë¶„ë¥˜ ì €ì¥"):
                tag_map = st.session_state.get("library_ai_tag_map", {})
                cat_map = st.session_state.get("library_ai_cat_map", {})
                if not tag_map and not cat_map:
                    st.error("AI íƒœê·¸ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë¶„ì„í•˜ì„¸ìš”.")
                else:
                    ids = [item.asset_id for item in (selected_assets or filtered)]
                    # íƒœê·¸ + ì¹´í…Œê³ ë¦¬ í•©ì³ì„œ ì €ì¥
                    apply_map: Dict[str, List[str]] = {}
                    for asset_id in ids:
                        combined = list(tag_map.get(asset_id, []))
                        if asset_id in cat_map:
                            combined.append(cat_map[asset_id])
                        apply_map[asset_id] = combined
                    updated = update_asset_tags(config.manifest_path, apply_map, keep_existing=keep_tags)
                    st.success(f"{updated}ê°œ ì—ì…‹ íƒœê·¸+ì¹´í…Œê³ ë¦¬ê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    st.rerun()

            if st.button("ì„ íƒí•œ ì—ì…‹ ì‚­ì œ"):
                ids = [item.asset_id for item in selected_assets]
                if not ids:
                    st.error("ì„ íƒëœ ì—ì…‹ì´ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    removed = remove_assets(config.manifest_path, ids, delete_files=delete_files)
                    st.success(f"{removed}ê°œ ì—ì…‹ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                    st.rerun()
        else:
            st.info("ì•„ì§ ì—ì…‹ì´ ì—†ìŠµë‹ˆë‹¤.")

    if page == "ë¡œê·¸":
        st.header("ë¡œê·¸")

        # â”€â”€ í…”ë ˆê·¸ë¨ ì—°ê²° ì§„ë‹¨ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        st.subheader("í…”ë ˆê·¸ë¨ ì—°ê²° í…ŒìŠ¤íŠ¸")
        col1, col2 = st.columns(2)
        with col1:
            st.write(f"BOT TOKEN: `{'ì„¤ì •ë¨' if config.telegram_bot_token else 'âŒ ì—†ìŒ'}`")
            st.write(f"ADMIN CHAT ID: `{config.telegram_admin_chat_id or 'âŒ ì—†ìŒ'}`")
        with col2:
            if st.button("ğŸ”” í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ ì „ì†¡"):
                if not config.telegram_bot_token:
                    st.error("TELEGRAM_BOT_TOKENì´ ì—†ìŠµë‹ˆë‹¤.")
                elif not config.telegram_admin_chat_id:
                    st.error("TELEGRAM_ADMIN_CHAT_IDê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    ok = send_telegram_message(
                        config.telegram_bot_token,
                        config.telegram_admin_chat_id,
                        "âœ… ìˆì¸  ìë™í™” ìŠ¤íŠœë””ì˜¤ í…”ë ˆê·¸ë¨ ì—°ê²° í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ì…ë‹ˆë‹¤.\nìŠ¹ì¸: ìŠ¹ì¸\nêµí™˜: êµí™˜",
                    )
                    if ok:
                        st.success("ì „ì†¡ ì„±ê³µ! í…”ë ˆê·¸ë¨ì—ì„œ ë©”ì‹œì§€ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
                    else:
                        st.error("ì „ì†¡ ì‹¤íŒ¨! ì•„ë˜ BOT ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.")

            if st.button("ğŸ¤– BOT ìƒíƒœ í™•ì¸"):
                if not config.telegram_bot_token:
                    st.error("TELEGRAM_BOT_TOKENì´ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    try:
                        resp = requests.get(
                            f"https://api.telegram.org/bot{config.telegram_bot_token}/getMe",
                            timeout=10,
                        )
                        data = resp.json()
                        if data.get("ok"):
                            bot = data["result"]
                            st.success(f"BOT ì •ìƒ: @{bot.get('username')} ({bot.get('first_name')})")
                        else:
                            st.error(f"BOT ì˜¤ë¥˜: {data.get('description', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
                    except Exception as exc:
                        st.error(f"BOT í™•ì¸ ì‹¤íŒ¨: {exc}")

            if st.button("ğŸ’¬ ë‚´ CHAT ID í™•ì¸"):
                if not config.telegram_bot_token:
                    st.error("TELEGRAM_BOT_TOKENì´ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    try:
                        resp = requests.get(
                            f"https://api.telegram.org/bot{config.telegram_bot_token}/getUpdates",
                            params={"limit": 5},
                            timeout=10,
                        )
                        data = resp.json()
                        updates = data.get("result", [])
                        if not updates:
                            st.warning("ìˆ˜ì‹ ëœ ë©”ì‹œì§€ê°€ ì—†ìŠµë‹ˆë‹¤.\në¨¼ì € ë´‡ì—ê²Œ ì•„ë¬´ ë©”ì‹œì§€ë‚˜ ë³´ë‚´ê³  ë‹¤ì‹œ í™•ì¸í•˜ì„¸ìš”.")
                        else:
                            for upd in updates:
                                chat = upd.get("message", {}).get("chat", {})
                                cid = chat.get("id")
                                cname = chat.get("first_name") or chat.get("title") or ""
                                st.info(f"CHAT ID: `{cid}`  ì´ë¦„: {cname}")
                    except Exception as exc:
                        st.error(f"CHAT ID í™•ì¸ ì‹¤íŒ¨: {exc}")

        st.divider()

        # â”€â”€ ì‹¤í–‰ ë¡œê·¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        local_log_path = os.path.join(config.output_dir, "runs.jsonl")
        if os.path.exists(local_log_path):
            with open(local_log_path, "r", encoding="utf-8") as file:
                lines = file.readlines()[-50:]
            records = [json.loads(line) for line in lines]
            st.dataframe(pd.DataFrame(records))
        else:
            st.info("ì•„ì§ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.")


def run_batch(count: int, seed: str = "", beats: int = 7) -> None:
    config = load_config()
    manifest_items = load_manifest(config.manifest_path)
    if not manifest_items:
        raise RuntimeError("ì—ì…‹ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì´ë¯¸ì§€ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
    for index in range(count):
        script = generate_script_jp(config, extra_hint=seed)
        mood = script.get("mood", "exciting")
        texts = _script_to_beats(script)
        mood_to_cat = {"mystery": "shocking", "exciting": "exciting", "informative": "humor"}
        cat = mood_to_cat.get(mood, "exciting")
        assets = []
        for _ in texts:
            asset = pick_asset_by_category(manifest_items, cat)
            if not asset:
                asset = random.choice(manifest_items)
            assets.append(asset.path)
        now = datetime.utcnow().strftime("%Y%m%d_%H%M%S")
        audio_path = os.path.join(config.output_dir, f"tts_{now}_{index}.mp3")
        voice_id = pick_voice_id(config.openai_tts_voices)
        tts_openai(config, "ã€‚".join(texts), audio_path, voice=voice_id)
        output_path = os.path.join(config.output_dir, f"shorts_{now}_{index}.mp4")
        bgm_path = match_bgm_by_mood(config, mood)
        render_video(
            config=config,
            asset_paths=assets,
            texts=texts,
            tts_audio_path=audio_path,
            output_path=output_path,
            bgm_path=bgm_path,
            bgm_volume=config.bgm_volume,
        )
        video_id = ""
        video_url = ""
        if config.enable_youtube_upload:
            result = upload_video(
                config=config,
                file_path=output_path,
                title=script.get("video_title", ""),
                description=script.get("pinned_comment", "") + "\n\n" + " ".join(script.get("hashtags", [])),
                tags=script.get("hashtags", []),
            )
            video_id = result.get("video_id", "")
            video_url = result.get("video_url", "")
        log_row = {
            "date_jst": datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S"),
            "title_ja": script.get("video_title", ""),
            "topic_theme": script.get("topic_theme", ""),
            "hashtags_ja": " ".join(script.get("hashtags", [])),
            "mood": mood,
            "pinned_comment": script.get("pinned_comment", ""),
            "voice_id": voice_id,
            "video_path": output_path,
            "youtube_video_id": video_id,
            "youtube_url": video_url,
            "status": "ok",
            "error": "",
        }
        try:
            append_publish_log(config, log_row)
        except Exception:
            pass
        _write_local_log(os.path.join(config.output_dir, "runs.jsonl"), log_row)


if os.getenv("RUN_BATCH") == "1":
    run_batch(
        count=int(os.getenv("BATCH_COUNT", "2")),
        seed=os.getenv("BATCH_SEED", "ì¼ë³¸ì–´ ë°ˆ ìˆì¸ "),
        beats=int(os.getenv("BATCH_BEATS", "7")),
    )
else:
    run_streamlit_app()